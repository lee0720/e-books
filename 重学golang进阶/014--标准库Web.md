---
html:
  embed_local_images: false
  embed_svg: true
  offline: false
  toc: true
print_background: false
export_on_save:
  html: true
  puppeteer: true
---
### 33.1 Web 框架

现在大家做的大部分工作都和 Web 开发有关系，我们学习的不是怎么使用 Go 语言来写一个 Web 程序，我们关键是通过 Web
开发分清楚对于一个复杂的系统我们要去怎么样去鉴定各自的边界，我们知道 Web
开发包含的内容非常的多，我们需要做的是怎么样把这些功能整合到一起，它们各自边界是什么，它们各自相关代码的流程是什么，这些东西没有什么复杂度的问题，关键要搞清楚流程。

我们学习 Web 框架的时候，很多人只能说照着对方的例子或者文档照抄，几乎没有尝试过怎么去优化或者发现 Web
框架本身有什么问题，是否适合当前应用，因为很难拿到一个衡量标准去做这件事。因为我们并没有真正理解框架内部是什么样的，只是因为熟悉它或者公司已经拿这个东西再用了。但是用的东西未必适合当前这个项目。到目前为止大部分人都停留在用代码往项目上靠，而不是因为某个项目去选择某类代码，这是两种不同的境界。

#### **Web Server**

首先我们分清楚 Web 开发严格来说分成两个部分，首先是 Web Server，然后是 Web Framework。这两个东西是完全不一样的，不要一说到
Web 开发就是 Web 框架之类的东西。只不过现在大部分人不会去写 Web Server，而会使用现成的 Nginx。或者说现在很多 Web
Framework 会内置 Web Server，但一定要搞清楚这两者并不是一回事。

Web Server 干什么用的呢，首先它会通过 Socket 去处理网络请求，就是说用这个东西来完成网络通信部分，那么我们在这上面基于 TCP 协议、在
TCP 协议之上走 HTTP 协议去解析。

对于 Web Server 来说更关注的不是说解析之后怎么去处理，它关注的重点在 Socket 和 TCP 层面，因为对于 HTTP
协议解析是很标准的内容，大家对于 HTTP 协议解析会遵循 1.1、HTTPS、2.0 标准，关键在于支持不支持。

对于大部分 Web Server 来说更关注的是 Socket 和 TCP 层面，有两个关键问题，第一个问题是尽可能多的接入量，经常早期有
C10K、C100K、C1000K 的问题，就是尽可能接入海量的请求，但是一个 Web Server
能接入多大的请求和它的吞吐量是两回事，因为接入量很多时候是跟操作系统有关系，操作系统有很多参数需要做优化才能提高接入量。

另外单机接入 100w 连接，并不表示 100w 连接都是在通信。就像我们说的我们可以一次性接入海量的
goroutine，并不表示有那么多东西在并行，你可以建 100w 并发任务，只是建立一个队列，每个任务会消耗一定的内存，仅此而已，并不表示有 100w
的并发任务同时执行，因为我们现在很清楚的知道并发到底怎么回事。任何时候真正能在执行的任务数量都是有限的。同样的接入量只是在网络上建立连接，但并不表示这个连接处于活跃和通信状态，任何时候处于活跃状态都非常少。所以接入量并不是衡量高性能标准。因为很简单的操作系统参数优化就可以做到和应用层面关注的东西不大。

接入量进来了之后，怎么提高吞吐量，这就需要 Web Server 做的一件事，操作系统完成了 Socket 连接之后，它会在操作系统内核提供相应的
Buffer 去完成相应的通信，最后你是否能把这些数据快速的处理掉这和你本身 App 层面的问题，你对这个吞吐量的处理是真正衡量程序的性能问题。

为了提高高速的吞吐量有不同的做法，有多进程模式，就是说一个进程负责监听其它进程负责快速处理；还有多线程或者是多线程加多进程甚至加上协程；甚至很多台机器堆叠。最终选择哪些东西跟你的业务需要和逻辑上并发需求需要。

我们需要搞清楚一个高性能的 Web Server 它本质上其实是很简单的过程，怎么样去处理 Socket，怎么样去接收 Accept
客户端，然后怎么样去处理 Read/Write。

#### **Web Framework**

Server 把数据分发到线性处理过程中，线性处理过程中它的上下文是由两个东西组成的，请求的相关信息 Request，这些信息是通过 HTTP
协议解析出来的，另外是要返回什么样的数据 Response，那么 Web Framework 本质上是完成这样的处理过程。所以 Web Framework
实际是给我们的逻辑处理提供一个基础环境，Web Framework 本身不在乎性能，在乎的是单次处理所消耗的资源。Web Framework
并不承担并发相关的东西。对他来说它处理的是单条流水线上的消耗。

这两个之间有一条边界，不要把它们混为一谈。虽然现在 Framework 里面内置 Server 或者 Server 里面内置
Framework，不管怎么做但是他俩本质上是完全不同的东西。在 Server 层面考虑的是高并发，在 Framework
层面考虑的是逻辑的易用性和单次性能。单次性能的衡量标准是内存占用，因为内存会涉及到 GC 问题，单次请求是否会有海量的 GC，第二是单次处理 CPU
的占用量，这两个相加涉及到单次请求所消耗的系统资源。所以这两个层面是有不同的含义。你研究的是 Server 还是 Framework 是不同的概念。

### Web Server 实现

对于 Go 语言很简单，首先 net/http 包装了相关的东西，它在 TCP 的基础之上已经包装好 Web Server
的相关内容。现在大部分语言都会提供已经包装好的这样的类库，那么我们需要研究就看看代码就可以了，并不算太复杂。

代码示例。首先创建 HTTP Server，这实际上是很简单的结构化对象，但是其中对我们最关键有几个参数。第一监听端口，监听哪块网卡上的 IP，IP 加上
port 构成唯一的值。常见的是服务器有两块网卡，一个对外、一个对内。接下来 Handler 指定接收到数据怎么处理，Handler
实际上实现一个接口，必须符合接口才可以。这个想法是拿到数据交给你，但不知道数据是谁，因为 Server 并不关心后面处理过程，也就意味着 Server
把数据交给后面环节并不关心后面使用的框架。框架可能是系统自带的，也可能自己开发的，甚至第三方的，对于 Server 来说不可能知道所有这个清单。最好的方式是
Server 和 Framework 中间用一个接口来实现这样一个协议。这样能确保可以用装配的方式确保可以向 Server 装配不同的 Framework。

    
    
    //定义类型
    type Hello struct{}
    
     //实现 ServeHTTP 接口方法
     func (Hello) ServeHTTP(w http.ResponseWriter, req *http.Request) {
         //这里处理数据属于 Framework 职责，对于 Server 来说根本不关心
         //因为这里属于 Framework 的内容
        fmt.Fprintln(w, "hello, world!")
     }
    
     func main() {
         //首先创建 http server，这实际上是很简单的结构化对象，但是最关键有几个东西
        srv := &http.Server{
            Addr:         ":8080",
            Handler:      new(Hello),
            ReadTimeout:  time.Second * 10,
            WriteTimeout: time.Second * 10,
        }
    
        log.Fatalln(srv.ListenAndServe())
     }
    

Server 有几个参数，尤其建议设置超时。

  * Addr：监听哪个端口，可以使用“:http”、“:https”，需要注意的是监听哪块网卡的 IP。严格上是由两部分组成的，IP+PORT 构成唯一的值
  * ReadTimeout、WriteTimeout：读写超时。在大多时候都应该提供超时操作，尤其在写 Server 程序时候一定要设置超时，假如客户端连接进来以后很长时间没有操作的话，最好关闭掉，因为现在写的是 Web Server 而不是 IM，如果建立 IM，它通过保持长连接来建立消息通道，但是它也会定期的发送心跳数据，比如每隔多长时间没有通信的话会发送心跳包告诉你我还活着。因为没有通信的话就算服务器端不关闭的话，中间的防火墙或者路由也可能把它关闭掉。这个完全靠 TCP 本身完全做不到，因为它可能会被忽略掉，多数时候是在用户协议层发心跳包。对于 HTTP 来说，它的通信是无状态的，如果长时间没有工作的话最好把它关掉，因为要处理海量的接入，如果没有任何操作的话，就把资源释放掉，下次再用的时候再建立连接。所以多数情况下 HTTP 是用短连接方式。除非特别声明要继续连续通讯，默认情况下我们会设置超时操作，保证连接时间，如果超过时间没有任何通讯则需要关闭了。如果从客户端去数据超过 10 秒读不到任何数据则关闭，同样的，如果 10 秒写不到客户端，也会关闭。
  * MaxHeaderBytes：DefaultMaxHeaderBytes 是 1MB。Apache、Nginx 通常设置为 8KB。
  * ConnState：监控客户端状态变化。
  * ErrorLog：设置日志记录器，输出内部错误。

    
    
    type Handler interface {
        ServeHTTP(ResponseWriter, *Request)
     }
    

这个接口很简单，只要实现 ServeHTTP 就可以，其实就是提供单次的上下文，一来一回。

ListenAndServe 方法做了两件事，第一个打开端口监听，包括处理绑定接收相关东西，然后开始提供服务，提供服务是 TCP 相关的内容，TCP
包括接入客户端然后把客户端发送的数据读出来，然后把 Framework 返回的数据写回客户端。所以这个方法包括监听和提供服务。所以对于 Server
来说看上去挺简单的。

#### **多进程监听**

上面是创建 Web Server 很简单的一个过程，这种方式是单进程加上并发单元方式处理海量并发。就是这样简单的几行代码就能实现高性能的 Web
Server，对于大部分应用绰绰有余。

除此之外，我们用多进程监听同一个端口，这样能确保灾难容错、负载平衡。

常见的 Go 模型是海量的接入，一个
Accept，然后为每个客户端创建并发单元，因为并发单元本身的性能提供海量的接入处理方式。但是这整个东西是在单个进程内的。单个进程内其实有很多问题，尤其是在面临海量连接的时候，也就意味着有上百万的并发单元，每个并发单元最少消耗
2Kb，这样整总体消耗也很可怕。对于单进程来说，实际上对于 GC
的压力是很大的。还有一个问题，单进程一旦挂掉以后，那么整个服务都崩溃了，你可能会用多台机器上去实现，但是这个前提是单台机器处理不了你才会多台机器，如果一台机器足足有余，仅仅是因为程序写的不好就用多台机器那是浪费而不是技术问题。如果单台机器的硬件资源根本没有消耗干净仅仅是因为技术做不到就用多台机器只能证明能力不够。用多台机器的前提是把单台机器的性能挖到了极端，单台机器没有办法接入了，我们才会尝试多台机器。

单进程对于我们来说处理一般的服务没有问题，但是一旦出现请求压力非常大的情况下，GC
可能给服务带来问题。第二个问题灾难容错，可能有很多个保姆程序来负责重启，但是重启的过程实际也有时间的，可能重启
Docker，重启会带来一定的代价，因为重启虽然时间短但是服务会中断，尤其是在高并发的状态下重启，会面临着洪水般的接入请求，因为所有断掉的连接都会尝试在同一时间接入，就算重启很快，在短时间内有海量接入，这样很可能会被防火墙屏蔽掉，误判为
ddos
攻击，这个防火墙未必是本机的，可能是机房防火墙或者上级防火墙，这样一来对于系统的不可控性就增加了。第三个问题是负载平衡。多网卡平衡、多进程平衡、多线程平衡，负载平衡是我们逃不过的一个话题。

我们使用 reuseport，这是 Socket 新的参数。单进程方式 Accept 永远是一个，Accept 实际上会成为一个瓶颈。因为 Accept
本身的分发是否能够做到公平性的负载平衡。reuseport 端口的好处是操作系统会把请求分发到多个 Accept
进程中，每个进程都可以监听同一端口，这样一来任何一个进程挂掉都没有关系只要有一个活下来就可以了，而且由操作系统来处理分发，相对来说更公平一点，对负载平衡算法来说更公正一点。

Go 语言当前版本不支持这个参数，所以我们使用第三方包 github.com/kavu/go_reuseport，简单的做了一次 Socket 包装。

    
    
    if err = syscall.SetsockoptInt(fd, syscall.SOL_SOCKET, syscall.SO_REUSEADDR, 1); err != nil {
        return nil, err
    }
    
    if err = syscall.SetsockoptInt(fd, syscall.SOL_SOCKET, reusePort, 1); err != nil {
        return nil, err
    }
    

syscall.SO_REUSEADDR 是重复使用当前的地址信息来确保程序重新快速启动时候快速回收端口。reusePort
是重复使用端口。这个是很简单的关于 TCP 的东西。

    
    
    package main
    
    import (
        "fmt"
        "net/http"
        "os"
        "strings"
        "time"
    
        "github.com/kavu/go_reuseport"
    )
    
    type R struct{}
    
    func (R) ServeHTTP(w http.ResponseWriter, req *http.Request) {
        fmt.Fprintln(w, strings.Join(os.Args[1:], " "))
    }
    
    func main() {
        //提供监听
        l, _ := reuseport.NewReusablePortListener("tcp4", ":8080")
        defer l.Close()
    
        srv := &http.Server{
            Addr:         ":8080",
            Handler:      new(R),
            ReadTimeout:  time.Second * 10,
            WriteTimeout: time.Second * 10,
        }
        //提供服务
        srv.Serve(l)
    }
    
    
    
    $ go build
    $ ./test hello,server A #启动一个
    $ ./test hello,server B #再启动一个
    $ curl http://localhost:8080 #请求 默认输出 serverA，因为没有跑满，不会把请求分发到 B，这是由操作系统内核来调度的
    $ curl http://localhost:8080
    $ curl http://localhost:8080 #关掉 serverA 后执行
    

实际上用两个进程提供服务。操作系统内核一般会记忆最后一次访问的 Server 默认情况下优先。这是内核实现的调度机制。但是起码看到在容错这块没有问题的。

可以把 Server
在一台机器上部署多个进程，这样好处是访问资源分流到多个进程上，每个进程上内存消耗内存回收压力小很多，挂掉任何一个没关系。还有个好处是升级，ServerA
正常运行，ServerB 启动新版本，然后 ServerA 版本关闭。

在 Go 语言中创建一个高性能 Server 很容易的。要么利用别的监听要么自己监听，然后提供服务，最后处理的客户端数据交到 R 对象里面，至于 R
对象内部怎么处理是 Framework 事情和 Server 没关系。

#### **Web Server 源码解析**

创建 Server，必须指定协议，也就是 Handler，Handler 属于 Framework
内容，其中包括高性能路由、大量的逻辑处理，action、model、数据库的东西。

Server 只做该做的事情，提供高性能接入，它不处理逻辑，Server 是个基础平台，不提供逻辑处理，逻辑处理属于应用层面上的事。从 Handler
开始属于应用的起点。路由可能是自定义的、第三方包或者系统自带的。

把它们拆开，研究 Server 只关心高性能、高并发。研究 Framework 只关心按线性看整个单次请求怎么处理，所以这两个切入点不一样。

ListenAndServe 监听提供服务，基本上是对网络包装进行调用，实际上是基于 TCP 协议实现。我们可以选择普通方式
ListenAndServe，也可以选 ListenAndServeTLS，TLS 实际上是 HTTPS，需要给证书，包含公钥证书私钥证书。

TLS/SSL 大概是一回事，只不过早期称之为 SSL，后来被互联网标准组织接手才叫 TLS，也就是说有版本号对应关系。TLS 关键会涉及到握手、数据加密。

ListenAndServeTLS 关键的一点是 setupHTTP2，在 Go 里面 HTTP2.0 版本实际上是建立在 TLS 基础上，也就是说只有在
Https 通讯的情况下才能打开 HTTP 2.0 通讯。

这涉及到 HTTP2，HTTP2 有两种方式，第一种提供 TLS 通讯，第二种直接在 TCP 通讯，不走
HTTPS，但是当前不同实现版本大部分情况下实现第一种，第二种基本上不愿意用，默认情况下都启动 TLS 加密，抛弃明文通讯。

网络编程实际上有些惯例。经过这么多年的发展已经非常成熟，都会按相同的模式，比如 TCP 服务端框架怎么去写、TCP
客户端怎么写，区别在于不同的语言技巧不太一样，但是整个过程已经固化了。

Serve
当提供服务的时候，用循环接入客户端请求，如果成功的话，会创建新的客户端包装对象，为每一个客户端请求创建并发单元，包装对象会涉及到不同的请求参数，这也是为什么使用
reuseport，因为在单个进程内创建海量的并发单元也是一种消耗。所以我们应该减少单个进程内的资源消耗，减少 GC 压力，减少调度器的压力。

在处理时 connReader 使用了
newBufioReader，并没有实现零复制机制，理论上会把所有数据从内核缓冲区复制出来。还有对于静态服务做的不是特别好，做的太简单不支持压缩、缓存。通常建议的方式是在前端挂一个专门用来处理缓存和静态资源的
Server，比如 H2O、Nginx，后面连接到 Go Server，Go Server 主要用来提供服务，不要在 Go Server
上优化静态资源访问。Go 虽然简单，用来提供作为服务的接入足够，但是并不适合用来处理静态资源场合。

Go 语言宣传可以快速的构建 Web 项目，实际上抛开第三方框架不说，本身自带的功能很弱，并没有想象的那么好。

### Web Framework 实现

整个 Web 开发包含 Server 和 Framework 两块，Server 传过来的请求，交给路由装置，在不同的编程语言有不同的说法，Go
语言通常把它称之为 Mux，它负责接收所有的请求，它会根据 URL 信息进行解析，然后把解析的结果对应到不同的处理器 Handler
上，所以说从框架上来说，Framework 是由 Mux 和不同处理器 Handler 构成。Handler 内部可能涉及 DB
操作、逻辑、模板引擎等用户层面逻辑。我们抛开用户层面不说，从框架角度来说基本的核心是由 Mux 和 Handler 组成。Mux
负责把不同的请求进行分发，这个请求可能是类似 restapi 的路径，而 Handler 不关心 Url，但是可能从 URL
中获取参数，但是它并不负责解析这些参数，因为解析参数是路由器处理的。它会像一个普通的对象去处理。如果我们需要开发第三方框架，首先要开发高性能路由，因为在路由处理的时候我们需要对
URL 路径提取它的动态和静态参数。

`/:hello/*` 方式称之为动态参数，它需要去匹配单个分支或者多个分支。`/a/b` 方式是静态参数，它需要完全匹配或者最大长度匹配。

对于 Mux
最核心的问题是性能，第一要处理快速的解析和转发，它的速度跟不上后面调用就谈不上，第二内存占用，面对海量请求情况下，解析过程不应该产生大量临时对象，导致 GC
有很大压力，Web 应用 QPS 每秒 10w 以上不算什么，可能单台机器单个进程每秒处理 2w 请求，如果每次请求需要产生 GC 需要处理对象，那么对于
GC
压力会非常的大，当写路由处理的时候零内存分配是非常重要的。而且我们会看到很多第三方框架在宣传文档里面都会提到零垃圾回收，这是对比很重要的参数，因为在海量高并发压力情况下这种临时对象的产生实际上对框架性能有非常大的影响。

在整个处理过程中，一定要想方设法减少临时对象的分配。比如说在逻辑对象中，某些对象是否可以重复使用，不要每次去创建可以用对象池，DB 连接前是否可以挂一套
cache。通常情况下解决方法是 Mux 到 cache 到 DB，但是在到 DB
节点上我们会做资源访问限制，可以通过信号量限制同时访问数据库的数量或者合并相同请求，因为 cache 奔溃了以后，第一次都会把请求刷到 DB 上去。

    
    
    type HelloHandler struct{}
    
    func (*HelloHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {
        fmt.Fprintln(w, "hello, world!")
    }
    
    func main() {
        //创建路由，这个路由是非常标准处理器
        mux := http.NewServeMux()
        //注册路由表，提供路径和具体下一级处理器
        mux.Handle("/hello", new(HelloHandler))
    
        srv := &http.Server{
            Addr:         ":8080",
            Handler:      mux, //处理器注册到 server 中
            ReadTimeout:  time.Second * 10,
            WriteTimeout: time.Second * 10,
        }
    
        log.Fatalln(srv.ListenAndServe())
    }
    

官方的路由是按照 UL 的最大长度匹配。那么我们创建一个路由，然后把这个路由注册到 Server 中。路由本身也是非常标准的处理器，server
根本不知道路由这种东西，对于 Server 来说就是请求进来交给
Handler，无非就是上下文中包含请求信息和用来返回的对象。路由是专门用来转发的处理器，路由是标准的处理器，只不过它不是用来处理业务而是专门用来做转发，它的内部注册了很多路径信息路由表，Server
请求过来以后，所有请求信息全部交给 Mux，因为对于 server 来说只提供了一个处理器，这个处理器会根据请求信息里面 URL 信息，URL
和注册的路由表进行匹配，匹配完了调用对应的下一级处理器，就这样一个过程。

首先注册路由表时候需要提供标准的处理器，就是要实现 `ServeHTTP(ResponseWriter, *Request)`
接口，因为用户创建处理器属于后置，最好的方式提供接口实现。

大多数情况下，我们只要提供一个函数。如果不想麻烦的话直接把函数注册进来。

    
    
    mux.HandleFunc("/hello", func(w http.ResponseWriter, r *http.Request) {
        fmt.Fprintln(w, "hello, world!")
    })
    

让一个函数实现一个接口也很容易。假设有个接口，无非一个包装，任何一种是和这个类型相同的函数就实现接口。

    
    
    //定义一个接口
    type A interface {
        test()
    }
    
    //包装 1:任何一种和这个类型相同的函数就实现 test 接口
    type FuncA struct {
        fn func()
    }
    
    func (f *FuncA) test() {
        f.fn()
    }
    
    //包装 2:任何一种和这个类型相同的函数就实现 test 接口
    type FuncB func()
    
    func (f *FuncB) test() {
        f()
    }
    

标准库提供一种便捷函数 HandleFunc，就是对 Handle 函数的包装，给函数的情况下会包装成 Handler
接口，很好心的写了一个便捷函数免得创建类型这么麻烦。

#### **Web Framework 源码解析**

ServerMux 是一个标准的处理器接口，内部用一个字典来保存路由表，每个路由信息其实有两部分组成的，第一个是 URL 匹配字符串，第二个是对应的处理器。

路由怎么处理的呢？这地方比较诡异，很平时用惯的习惯不太一样，第一可以同时注册 /test 和 /test/
两个路径，互不干扰，正常情况下我们会把这两个路径处理成相同的逻辑。第二仅注册 /test/，会重定向
/test，它的最长匹配指的是路由表为蓝本，而不是用户请求为蓝本。它内部做了一次跳转，这种跳转需要到客户端做二次请求的，没有在服务器端直接把这两个路径处理成一样的。

因为多数情况下我们不能希望用户输入的完全匹配，我们会尽可能的允许用户犯错，然后实现最佳匹配。但是很显然标准库提供的默认路由规则有点反人类，它的匹配算法非常简单，长度优先，用
for
循环处理所有路由表，使用用户路径信息按长度匹配找到最长的匹配路径。所以很多时候第三方框架匹配比标准库快多少倍，是因为标准库写个太烂，没有使用任何高端的数据结构。标准库不支持参数化，完全是静态匹配。

标准库的路由纯粹是用来写 helloworld 性能测试，给第三方框架提供一个基准，根本没有办法做正常的业务开发。因为我们要的各种各样的功能都没有。

自带的标准处理器还是有的，404 错误、跳转。

我们 Web 开发，整个 Web 请求是个链式调用，Server、Mux、中间件、处理器、逻辑。

正常情况下，一个请求可以分解成多个处理器的套用，每个处理器只处理其中一个部分，例如修正路径、负载平衡、缓存。可以把这些常用的功能做成通用的处理器，最后才是定制逻辑，可以按照功能把它们串联起来，这部分称之为中间件。中间件本质上也可以实现成处理器，只不过它被设计成通用的，重复使用的，可以装配模式组合成完整处理过程。

大部分做 Web 开发都会选择第三方的框架。

Go
是一门编程语言。编程语言由语法、标准库、文档这些东西组成，语言标准库最大的责任提供的是基础组件，例如数据同步、管道、原子操作、加密算法，标准库提供是非常基础的算法，另外其他包装的一些东西，容器类对象、模板引擎、Mail、Rpc
很少有人用而使用第三方的。因为标准或自带的东西速度不够快，而且会产生大量零临时对象。

整个标准库分成两块，一块是最基础的组件算法，一块是为了我们日常开发提供的样本，比如 HTTP、Mail、RPC、SMTP
我们很少使用自带的这些东西。标准库提供的是通用功能，不应该提供任何的扩展。很多语言标准库和扩展库是分开的。

官方还提供了 Client 操作，它的基本架构还是值得学习的。如果我们设计客户端，我们可能会处理请求，处理返回，内部处理 Http 协议等。Client
操作官方设计抽象出 HttpClient，HttpClient 里面不处理任何 HTTP 协议相关东西，它专门用一个底层组件处理协议，就是说
HttpClient 属于抽象层面，抽象层面提供标准的 API 层面。协议层面会涉及到 TLS 的升级，HTTP2 的支持，协议默认是
socket，但是测试可以实现伪协议，把 socket 通信改成本地 API 调用，测试只要实现 API
就可以了根本不需要通过网络协议实现。所以协议层面我们可以通过相同的 API 来处理不同的环境，这是很常见的设计，把可冻结的部分和可变化的部分分离掉，API
是固定的就可以保证标准库的兼容性。

我们注意到 Client 客户端存在一些问题，协议层面会涉及 TLS 的升级、HTTP2 支持。还有一点是 HTTP 不一定基于
Socket，如果测试可以实现伪协议绕开通讯改成本地 API 调用。测试的时候只需要实现相应的 API，根本不需要通过网络协议实现。我们可以用相同的 API
处理不同的环境，这个环境可能有 TLS、HTTP2 甚至伪协议。

在现代网络环境下，协议是变数最大的一个部分，有可能有各种各样的原因导致协议发生很多的不同。如果底层协议固定死对测试来很麻烦。

一个标准的客户端包含 Transport 和 Jar。Transport 处理底层通讯的，Jar 是 cookie
处理。我们可以学习到对于一个复杂的组合体怎么样拆分。

所有的底层处理交给专门协议处理器处理。协议处理器 Transport 只处理和协议有关的内容，比如 HTTP 协议解析、HTTP2 处理、TLS
握手，这个内容相对来说和用户 API 无关。

### 小结

net/http 对于我们来说，除了 Server
以外，我们更大程度把它当成一个独立的项目研究它的架构体系，它的架构体系有很大的借鉴作用，我们关注的焦点不是代码写的怎么样，从一定程度上来说，它代表了系统程序员怎么样去认识这个架构，这个架构怎么处理的，各个模块怎么协作的。

  * <https://blog.golang.org/http-tracing>
  * [TCP/IP networking](https://appliedgo.net/networking/)
  * [HTTP/2 Server Push](https://blog.golang.org/h2push)
  * [HTTPS proxies support in Go 1.10](https://medium.com/@mlowicki/https-proxies-support-in-go-1-10-b956fb501d6b)
  * <https://blog.cloudflare.com/the-complete-guide-to-golang-net-http-timeouts/>

> **感谢各位的光临哟！！**
> **获取更多资源:掘金小册,gitchat专栏,极客时间等资源；**
> **请到闲鱼店：583128058yanghon**
> **啊呜呜~~~**