---
html:
  embed_local_images: false
  embed_svg: true
  offline: false
  toc: true
print_background: false
export_on_save:
  html: true
  puppeteer: true
---
### 测试是什么

一个完整的软件有两个方面组成，第一是面向普通用户的软件产品，第二是面向公司的代码产品。代码需要不停更新迭代，也是一个产品。测试用于监管代码质量，测试本身也是算法，测试代码也需要维护和升级，测试和代码是相辅相成的。

程序是算法加数据。简单的逻辑是一些算法指令，算法执行过程当中需要数据，这个数据可能在数据库里、也可能在文件里，算法和数据分离。

测试也是，测试逻辑和测试数据分离。测试数据是场景、上下文、状态，维护测试逻辑不用关心测试数据，在保证测试逻辑正确的情况下，调整测试数据形成更严密的测试。测试逻辑可能由编码人员编写，编码人员未必了解测试场景，他没有办法提供很完整的测试数据。测试数据可能由
PM 或者专职人员收集，可能来源于最早的设计文档，也可能来源于运营期间的数据。

### 单元测试

以单元测试确保逻辑正确，并持续跟踪。

  * 测试代码同样放在目标包内，以 _test.go 结尾。
  * 测试函数名为 TestName 格式。
  * 测试函数内用 testing.Error、Fail 等方法指示测试失败。
  * 编译命令（go build）会忽略测试源文件。

单元测试的主要目的是确保逻辑正确，对代码进行持续跟踪。一般开发人员编写单元测试，测试人员提供测试样本数据。

#### **单元测试基本命令**

    
    
    $ go test #测试当前包
    $ go test math #测试指定包
    $ go test ./mylib #使用相对路径
    $ go test ./... #测试当前及所有子包，但不包括 vendor
    $ go test ./vendor/... #测试 vendor 下所有包
    

#### **测试函数示例**

    
    
    func TestDemo(t *testing.T) {
        t.FailNow()
    }
    

简单的单元测试在特定文件里提供名字，以 Test 为前缀，后面名字首字母大写。

    
    
    $ go test
    $ go test -v #输出详细信息
    

#### **测试缓存**

为提高测试效率，相关测试结果会缓存。

  * `go test` 测试当前包，缓存编译结果，但不缓存测试结果。
  * `go test package...` 缓存测试结果，输出（cache）提示。
  * `go clean -cache -testcache` 清除编译和测试缓存。
  * `-count` 等参数会阻止缓存。

测试会被缓存，`go env` 可查看缓存目录环境变量
GOCACHE，缓存目录除了缓存编译结果还会缓存测试结果。它有一些基本的规则，比如测试当前包每次都会重新测试，测试第三方依赖包会检查代码有没有修改。因为依赖包修改的可能性比较小，可以加快测试速度。

清除缓存命令中 `-cache` 清除编译结果，`-testcache` 清除测试结果。有些参数会导致缓存失效，例如 `-count` 参数。

    
    
    $ go test math
    ok math 0.008s
    $ go test math
    ok math (cached)
    $ go clean -testcache
    

#### **测试命令行参数**

  * `-args`：向可执行文件传入命令行参数。
  * `-c`：仅编译，但不执行测试。
  * `-i`：安装与测试相关的包，但不执行测试。
  * `-json`：将结果输出为 JSON 格式。
  * `-count`：重复测试次数，默认 1。
  * `-list`：使用正则表达式列出测试函数，不执行。
  * `-run`：指定测试函数，正则表达式。例如 `-run "Add"`。
  * `-parallel`：并发执行，默认 GOMAXPROCS。例如 `-parallel 2`
  * `-timeout`：全部测试累计时间超时将引发 panic，默认 10 分钟。例如 `-timeout 1m30s`
  * `-v`：输出详细信息。

#### **测试断言**

  * Fail：失败，继续执行当前测试函数。
  * FailNow：失败，立即终止执行当前测试函数，相关 Failed。
  * SkipNow：跳过，停止执行当前测试函数，相关 Skip、Skipf、Skipped。
  * Error：Fail+Log，相关 Errorf。
  * Fatal：FailNow+Log，相关 Fatalf。
  * Log：输出错误信息，仅失败或 `-v` 时输出，相关 Logf。

断言函数表示告诉执行器标记什么失败，对执行器施加什么影响。

#### **子测试**

将复杂测试逻辑拆分子测试，以套件（suite）方式组合。

  * 更便于编写初始化（setup）和清理（teardowm）逻辑
  * 将无关代码（比如初始化等）外置，直接观察子测试结果

    
    
    func TestSuite(t *testing.T) {
        time.Sleep(time.Second)
        println("setup")
        defer println("teardown")
        t.Run("A", func(t *testing.T) { time.Sleep(time.Millisecond * 10) })
        t.Run("B", func(t *testing.T) { time.Sleep(time.Millisecond * 20) })
        t.Run("C", func(t *testing.T) { time.Sleep(time.Millisecond * 30) })
    }
    

我们很少对一个函数测试，而是对完整的逻辑测试。Go
提供的单元测试没有初始化和清理逻辑。可以利用套件测试完整的逻辑。套件可以模拟初始化、清理、执行多个子测试函数，每个子测试不受外界影响。

    
    
    $ go test -v -run "Suite/B" #直接测试子测试 B
    

#### **并行测试**

多包测试以并行方式运行，单包内测试函数默认以串行方式执行。

  * 调用 t.Parallel 的测试函数以并行方式执行，其他依旧
  * 单函数多次测试（-count）不以并行方式执行
  * 子测试同样支持并行测试

    
    
    func TestA(t *testing.T) {
        t.Parallel()
        time.Sleep(time.Second)
    }
    func TestB(t *testing.T) {
        time.Sleep(time.Second)
    }
    func TestC(t *testing.T) {
        t.Parallel()
        time.Sleep(time.Second)
    }
    

默认情况下多个包之间是并行，一个包内是串行。上面有三个测试，A 和 C 并行执行，B 串行执行，假设每个执行一秒，A 和 C 执行一秒，B
执行一秒，总体时间从三秒变成两秒。

默认情况下所有测试函数在一个并发单元执行。测试执行器启动后，一个测试结束后才会执行下一个形成串行执行。并行的话，并发单元立即返回不等待测试结果，测试结果使用信号返回。建议互相不共享数据资源的函数并行执行。

#### **表驱动**

表驱动（table drive）将测试数据和测试逻辑分离，更便于维护和扩展。

  * 内部可用子测试，确保所有测试数据全部执行，并观察
  * 代码模板化，便于不同人员维护
  * 变量使用短名，输出信息易于阅读

    
    
    func add(x, y int) int {
        return x + y
    }
    func TestAdd(t *testing.T) {
        var tests = []struct {
            x    int
            y    int
            want int
        }{
            {1, 1, 2},
            {2, 2, 6},
            {3, 2, 5},
        }
        for _, tt := range tests {
            o := tt //并发执行时要避免闭包效应
            t.Run("", func(t *testing.T) {
                t.Parallel()
                got := add(o.x, o.y)
                if got != o.want {
                    t.Errorf("add(%d, %d): want %d, got %d", o.x, o.y, o.want, got)
                }
            })
        }
    }
    

写一个程序把数据和算法分离。通常写一个函数，把需要的数据作为参数方式注入，再调用函数。同理，对函数 `got := add(o.x, o.y)`
进行测试，提供两个参数得到结果，进行结果判断。

数据部分定义 tests
结构体类似于表结构，每行有三列，这些数据包括函数需要的参数和期望得到的结果，这样就模拟一个数据表。接下来循环遍历测试数据执行算法，所有的测试用子测试的并行方式执行。判断实际得到的结果和期望得到的结果是否相同。如果相同代表成功，如果失败打印出格式化数据。使用格式化数据是因为测试结果输出到软件测试的工作系统，这个系统对结果进行分析，解析出来做统计报表发给对应的某个人。

上面测试通过输出结果知道，执行了三组数据，其中 2+2 期望得到是 6 实际得到的是 4。

还要注意到，我们测试的是多行数据，任何一行出错是否终止这个循环？只标注这次测试其中某个地方出错并不终止这个循环。表驱动的方式做测试的时候，一定要把所有的行全部执行完成，样本越多越容易精确定位。

表驱动代码的维护很干净。把单元测试公开，通过注入新的测试数据检查算法是否有问题。数据部分的维护和测试逻辑的维护可能不是一个人。

    
    
    func div(x, y int) int {
        return x / y
    }
    func TestDiv(t *testing.T) {
        var table = []struct {
            x       int
            y       int
            expect  int
            recover bool
        }{
            {10, 5, 2, false},
            {10, 0, 0, true},
        }
    
        // ---
    
        for _, row := range table {
            func() {
                defer func() {
                    err := recover()
                    if r := err != nil; r != row.recover {
                        t.Errorf("div(%d, %d): expect recover %v, actual %v", row.x, row.y, row.recover, r)
                    }
                }()
    
                actual := div(row.x, row.y)
                if actual != row.expect {
                    t.Errorf("div(%d, %d): expect %d, actual %d", row.x, row.y, row.expect, actual)
                }
            }()
        }
    }
    

有些时候测试需要捕获一些异常。比如除法很典型的错误是被零整除，任何系统被零整除都会抛出异常。有些测试会检查是否对这种异常做出相应的处理。

上面例子除了期望得到一个值以外，还增加了额外字段表示是否能捕获到某一个错误。由于需要捕获异常，构建成匿名函数的调用捕获。用单个匿名函数实现完整的单次测试场景，然后分离，便于维护。用参数拷贝的方式可以避免闭包对测试结果的影响。从代码重构的角度来说，逻辑测试的框架和细节分离。

#### **示例代码**

    
    
    func ExampleAdd() {
        fmt.Println(add(1, 2))
        fmt.Println(add(2, 2))
        // Output:
        // 3
        // 4
    }
    
    
    
    $ go test -v
    

最大用途并非测试，而是生成帮助文档。比对输出（stdout）结果和特定注释是否一致。

不能用内置 print、println，它们输出到 stderr。

以 Example 为前缀，没有参数，没有断言，通过输出
stdout，再写一个注释。执行器捕获输出结果和注释进行比较，如果一样就是对的。它用来生成帮助文档，工具提取这样的函数在文档里插入例子。

单元测试的目的是保证代码是正确的，表驱动方式确保逻辑符合需求，生成帮助文档。

### 性能测试

获知算法执行时间及内存开销：

  * 以 Benchmark 为函数名前缀，同样保存在 *_test.go 文件中
  * 用 `go test -bench` 执行
  * 如仅执行性能测试，可用 `run=NONE` 忽略单元测试

    
    
    func add(x, y int) int {
        return x + y
    }
    func BenchmarkAdd(b *testing.B) {
        for i := 0; i < b.N; i++ {
            _ = add(1, 2)
        }
    }
    
    
    
    $ go test -v -bench "Add"
    

算法要保证逻辑和性能符合要求。性能测试除了执行时间，还会涉及内存开销。写一个算法其实要各种要求，可测试性、可维护性、可阅读性、内存资源占用最少，代码复杂度够低，甚至还要测试下是否有资源泄露。

测试框架循环重复执行算法，把总时间除以循环次数得到结果，从统计学来说，采样次数越多，平均值越接近于最合理的测量。因为各种各样的环境因素没有办法做到完全物理隔离测试。比如当前操作系统对它的调度，优先级、时间片、中途是否意外因素导致中断。

函数执行影响它的性能有很多外在的原因。第一执行过程中是否立即被调度到 CPU
上，第二执行过程中有没有上下文切换，第三执行过程中是否有内存唤入唤出。所以基于统计上的理论，执行足够多的次数取平均值，这个平均值接近于最合理的理想化的执行时间。

#### **性能测试循环次数**

    
    
    func BenchmarkAdd(b *testing.B) {
        println("B.N =", b.N)
        for i := 0; i < b.N; i++ {
            _ = add(1, 2)
        }
    }
    
    
    
    $ go test -bench .
    BenchmarkAdd-4
    B.N = 1
    B.N = 100
    B.N = 10000
    B.N = 1000000
    B.N = 100000000
    B.N = 2000000000
    2000000000 0.33 ns/op
    

通过逐步增大 B.N 值，反复执行测试函数，直到运行时间足够（默认 1 秒），以能获得准确测量结果。

add 算法可能执行 1ns，也可能执行 100ms，怎么知道执行多少次最合理的呢？如果自己写测试框架的单元测试执行器，怎么确定 b.N 是多少才最合理呢？

实际上多次调用这个函数，每次对 N 进行修改，首先把 N 设为 1，大概就知道 add 算法单次执行大概时间是多少，接下来会逐步增加这个值，比如
100，执行后发现总的花费时间不足以测量就继续加大这个值，直到花费时间比较方便做平均值计算。也就是通过时间的探测一点点累加达到某一个特定的阈值，这个阈值是一秒。所以测试框架会多次调用
BenchmarkAdd 函数，设定不同的 b.N 值，直到某一次可以得出结果。

为什么 BenchmarkAdd
函数中循环而不是循环调用这个函数，是因为函数调用和循环调用有计算误差的，用循环本身性能开销会很小，任何一次函数调用需要准备很多场景，包括堆栈帧分配。最好的思路是一次函数调用内部执行多次，N
是通过不停的加大这个值，最后得到一个相对合理值。

#### **设定执行时间**

    
    
    func sleep() {
        time.Sleep(time.Second)
    }
    func BenchmarkSleep(b *testing.B) {
        for i := 0; i < b.N; i++ {
            sleep()
        }
    }
    
    
    
    $ go test -bench . -benchtime 5s
    

某些耗时目标，默认循环次数过少，取平均值不足以准确计量性能。可用 benchtime 设定测试时间来增加循环次数。

强制执行时间，指定测试 5 秒钟指的是如果循环次数足够多不会执行 5 秒，只有单次时间超过阈值才会执行 5 秒。5 秒指的是单个测试数量不够的情况下才会凑成
5 秒。说白了是给测试框架一个建议，循环次数不够就得达到指定这个时间。

如果单元测试算法单次执行时间超过某个阈值，可能不会做很多次循环，这是单元测试框架基本的理论。在分析报告里出现这样的数据，需要关心是否能接受。如果接受就确定的确要花这么长时间，如果不接受是什么原因造成的。比如测试
IO 读写操作本来是 100 毫秒测试结果变成 1 秒，第一种原因是算法出错，第二种是执行环境，比如硬盘快挂了、备份系统启动了、目录下产生太多文件。

所以有很多意外的原因导致测试结果差别非常大，需要在统计报告里做特殊的标注，这些未必是算法造成的，有可能是意外原因造成的。

#### **设定执行核**

在现代计算机指定 CPU 核并行测试，一个算法是在多个核同时并发的也有可能会有差别。比如在单个核上执行算法对硬盘 IO 来说是独享的，在多个核同时执行 IO
会分散会不会对算法有影响？

    
    
    $ go test -v -bench "Add" -cpu 1,2,4
    

Go 语言提供 CPU 参数指定不同 CPU 进行测试，指定 1 个核、2 个核、4
个核对一个算法测三遍。使用核的数量不同，我们可以看到这个性能是否有明显的波动。

大部分现代系统架构都会支持并发和并行。在单台机器上多核并发并行和单次测试的结果是不一样的。如果随着核的数量增加时间会线性增长，考虑算法是否要优化，因为这个算法对并发处理不够好。

#### **计时器**

    
    
    func BenchmarkAdd(b *testing.B) {
        time.Sleep(time.Second)
        b.ResetTimer() //重置
        for i := 0; i < b.N; i++ {
            _ = add(1, 2)
            if i == 1 {
                b.StopTimer() //暂停
                time.Sleep(time.Second)
                b.StartTimer() //恢复
            }
        }
    }
    

如在测试函数中要执行额外操作，那么应暂停计时器。

测试框架内部有一个计时器。写测试代码时，会有额外的初始化的信息干扰计时器，因为计时器是从函数开始执行到结束，函数中间准备数据时间不应该计算。计时器重置归零，准备数据时间不算，中途可以计时器临时暂停再恢复，确保相对准确的结果。

上面可以看到总时间花得很多，但是对测试函数没有影响。

#### **输出内存开销**

    
    
    //go:noinline
    func heap() []byte {
        return make([]byte, 1024*10)
    }
    func BenchmarkHeap(b *testing.B) {
        for i := 0; i < b.N; i++ {
            _ = heap()
        }
    }
    
    
    
    $ go test -bench . -benchmem
    

输出结果包括单次执行栈内存分配总量和次数。也可在函数内调用 b.ReportAllocs 输出内存信息，无论使用 benchmem 参数与否。

上面输出单次操作花多长时间，单次操作在堆上分配多少内存，单次操作一共有几次内存分配。内存分配涉及垃圾回收器影响，有很多第三方库是零分配。

为什么要测试内存？在堆上分配内存会影响到垃圾回收，内存分配器要额外做一些函数调用，所以测试时间并不是唯一的衡量标志。严格来说，测试时间、单次操作分配多少内存、单次操作执行几次分配才是完整的测试报告。第一，单次操作花费多少时间。第二单次操作在堆上分配多少内存。第三单操作执行多少次分配操作。

如果单次分配内存非常多，它会涉及小对象和大对象，如果是大对象可能会放在 LOH 上，Java 默认是
G0，直接放到二级代龄上，它的生命周期非常长，有可能在短时间之内消耗了大量的内存，得不到及时回收造成大量换入换出。

内存的分配测试：

    
    
    const max = 1 << 20
    
    func array() [max]byte {
        var data [max]byte
        for i := 0; i < len(data); i++ {
            data[i] = 1
        }
        return data
    }
    
    func slice() []byte {
        data := make([]byte, max)
        for i := 0; i < len(data); i++ {
            data[i] = 1
        }
        return data
    }
    
    func BenchmarkArray(b *testing.B) {
        for i := 0; i < b.N; i++ {
            _ = array()
        }
    }
    
    func BenchmarkSlice(b *testing.B) {
        for i := 0; i < b.N; i++ {
            _ = slice()
        }
    }
    
    
    
    $ go test -v -bench "(Array|Slice)" -benchmem
    

上面例子有两个函数，一个返回初始化过的数组，一个是返回切片。性能测试这两种算法各自消耗多少内存。

### 代码覆盖率

单元测试和性能测试关注代码质量，那么代码覆盖率（code coverage）就是度量测试自身完整和有效性的一种手段。

  * 分析测试代码编写质量
  * 发现死代码（dead code）

    
    
    func add(x, y int) int {
        return x + y
    }
    
    func div(x, y int) int {
        return x / y
    }
    
    func TestAdd(t *testing.T) {
        if add(1, 2) != 3 {
            t.FailNow()
        }
    }
    
    func TestDiv(t *testing.T) {
        if div(10, 2) != 5 {
            t.FailNow()
        }
    }
    
    
    
    $ go test -cover -v
    

单元测试保证算法是正确的，性能测试确保执行效率。单元测试尽可能覆盖代码，性能测试针对核心算法。

单元测试的评估标准是代码覆盖率。什么叫代码覆盖率？代码覆盖率会输出一个结果，检查覆盖了多少的代码。通过代码覆盖率检查大概知道源码执行了多少行，通过百分比知道覆盖面有多少。

通过覆盖率可以测试是否完整的监控程序代码。很多公司对覆盖率有基本的要求，比如 80%
以上。哪些代码执行了多少次。通过百分比做出基础的衡量，表达是不是完成了完整的测试覆盖。

  * 第一保证所有的代码处于监管状态。
  * 第二保证所有的功能都是正确的。
  * 第三保证所有的性能都是符合要求的。

覆盖率测试是对单元测试做出一个预警，单元测试首先在测试结果保证正确的情况下，要保证单元测试有效果。

通过覆盖率能检查出数据合不合理，如果数据合理的情况下，为什么还会有代码没有被执行到？一种原因是代码写错了，第二种原因是死代码。覆盖率测试对测试的代码和目标做一个初步的质量管控。

#### **输出代码覆盖率检查结果**

有些时候可能需要详细的信息，在哪些文件覆盖，输出到文件里。以函数为单位输出代码覆盖率结果。

    
    
    $ go test -cover -coverprofile cover.out #代码覆盖率输出到文件
    $ go test -cover -covermode count -coverprofile cover.out #cover
    $ go tool cover -func=cover.out #以函数为单位输出代码覆盖率结果
    $ go tool cover -html=cover.out #浏览器输出代码覆盖率结果
    

覆盖率测试可以选择覆盖检查模式，count 指执行次数。测试完成以后会输出基本的测试报告，比如覆盖率多少，覆盖率 50%
表示两个函数但是测试只执行一个函数测试。

我们可以输出测试报告，可以看到哪些文件被测试到了，覆盖率为零表示没有被测试。

还可以用浏览器输出。我们看到红色的部分表示代码没有被覆盖到。没有被覆盖到的有几个原因，第 1 个没有写单元测试，第 2 个没有执行单元测试。第 3
个如果是局部代码没有覆盖到可能测试数据不够或者死代码。另外鼠标移上去可以看到执行多少次。如果执行次数非常多应该考虑把这个函数内联减少调用函数的性能开销。

### 性能监控

采集测试或运行数据，分析问题，针对性改进算法。

  * 开启 profile 会导致性能损失
  * 不同 profile 之间存在干扰，建议每次采集一种
  * 定期将采样结果保存到文件，手工或自动检查
  * 如执行性能测试，可设置 benchtime 参数，以确保有足够采样时间

单元测试、性能测试，代码覆盖率都是基于代码级别的。性能监控是基于项目运行状态的测试，我们可以基于性能测试采集，也可以基于 net/http/pprof
线上采集，采集完通过 URL 的把采集数据捕获下来，长时间运行抓取数据，记录下来进行离线分析。

单元测试或者性能测试都是对单个块或者算法做出测试。性能监控或者性能监测，捕获运行期一些状态。我们在运行期可能需要长时间运行，然后得到一个状态，我们需要对这个状态作出统计，CPU
占用率和内存的占用率。产品测试呢包含实验室的测试和生产环境的测试。单元测试或者性能测试都属于实验室状态。首先保证在实验室状态的极端性能达到我们符合的要求。在生产环境下我们还要进行捕获。

#### **性能监控目标**

  * cpu：确定主动消耗 CPU 时间的位置
  * heap：内存分配采样，监视内存使用和泄露
  * threadcreate：系统线程创建报告
  * goroutine：当前所有 G 堆栈报告
  * block：同步等待位置，默认关闭，使用 SetBlockProfileRate 启用
  * mutex：锁争用报告，默认关闭，使用 SetMutexProfileFraction 启用

选择的目标有很多，比如 CPU、堆上内存分配等导致性能问题的一些东西，选取其中一个进行监控。线上进行采集需要引入 `import
_"net/http/pprof"` 激活包，这个包在后台持续采集数据。

#### **性能采集参数**

  * cpuprofile：保存执行时间采样到指定文件。例如 `-cpuprofile cpu.out`
  * memprofile：保存内存分配采样到指定文件。例如 `-memprofile mem.out`
  * memprofilerate：内存分配采样起始值，默认 512KB。例如 `-memprofilerate 1`
  * blockprofile：保存阻塞时间采样到指定文件。例如 `-blockprofile block.out`
  * blockprofilerate：阻塞时间采样起始值，单位：纳秒
  * mutexprofile：保存锁针用采样到指定文件
  * mutexprofilefraction

#### **线上执行**

    
    
    import (
        "net/http"
        _ "net/http/pprof"
    )
    
    func main() {
        http.ListenAndServe(":8080", http.DefaultServeMux)
    }
    
    
    
    $ go run main.go #web
    

启动一个 Web Server，利用线上监控的接口注入线上监控状态。用浏览器打开 http://localhost:8080/debug/pprof
实时监控的状态，包括多少阻塞、多少并发单元，多少堆分配等。

标准库中有大量的测试函数。下面的方式通过单元测试方式采集标准库包 net/http，采集内存使用率和 CPU
使用率两组数据。输出到两个文件中，这个测试时间比较长。

    
    
    $ go test -run NONE -bench . -memprofile mem.out -cpuprofile cpu.out net/http
    

#### **查看采集结果**

针对文件进行分析，简单的方式是命令行的工具，新版提供一个 WebUI，打开内存占用文件：

    
    
    $ go tool pprof http.test cpu.out #线下检查
    $ go tool pprof -http=:8080 http.test mem.out
    

建议用新 Web UI 代替命令行输出，含火焰图。

#### **视图支持**

  * top：列表方式
  * flat：仅当前函数，不包括它调用的其他函数
  * sum：列表前几行所占百分比总和
  * cum：当前函数调用堆栈累计
  * Graph：图方式
  * Flame Graph：火焰图方式
  * Peek：上下文调用，谁调用它，它调用谁
  * Source：查看源码哪一行导致内存开销大
  * Disassemble：反汇编

我们用 CPU 文件作为例子：

  * `top` 命令看有哪些函数调用，哪些函数调用占用的时间非常多。我们可以看到系统调用非常多占用时间超过 30%。也就是线上系统有大量的系统调用导致时间浪费非常多。
  * `peek syscall.Syscall` 检查调用关系。看有哪些函数在调用系统调用，我们看到读和写操作也是系统调用，它们各自占比是多少。HTTP 大量的 Socket 操作是很标准 IO 操作，它不是缓存 IO。通过调用关系找到谁调用我导致时间多或者我调用谁时间多。
  * `list syscall.Syscall` 通过分析源码，哪些调用导致时间占非常多。在源码中定位哪行调用导致花费这么多时间。
  * `web` 输出调用关系图，看上去更直观一些。可以缩小范围指定围绕哪个函数进行分析 `web webRequest` 围绕 webRequest 的核心来检查它的相互调用关系。

> **感谢各位的光临哟！！**
> **获取更多资源:掘金小册,gitchat专栏,极客时间等资源；**
> **请到闲鱼店：583128058yanghon**
> **啊呜呜~~~**