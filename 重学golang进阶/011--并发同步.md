---
html:
  embed_local_images: false
  embed_svg: true
  offline: false
  toc: true
print_background: false
export_on_save:
  html: true
  puppeteer: true
---
### 同步概况

同步是并发最后一个环节。

当两个并发单元共享同一个数据的时候需要同步处理。这里的并发单元不限于进程中的两个线程，也可能两个进程，甚至两台服务器。同步处理不局限共享同一块内存，当两个进程共享同一个文件给文件加锁都是同步处理，在数据库中启动一个事务或者启动乐观锁都是同步处理。共享同一资源产生数据竞争都需要做同步处理。

标准库 `sync` 包专门用来做同步的，它由条件、锁，锁分为互斥和读写，WaitGroup
等组件构成。任何一种语言的同步组件使用频率非常高，性能要求非常苛刻，设计上都会非常精巧。平时写业务代码只是为了完成逻辑，但是像同步这种偏系统型的代码实现有很多很精巧的设计，我们去设计粒度会更粗糙不会有这么精巧。所以对于同步代码阅读和学习有助于开阔对代码控制能力的眼光。

### 不同的同步方式

在不同场景选择合适的同步方式。

  * channel：存在生产、消费等不同角色。
  * mutex：相同角色间的逻辑竞争保护。
  * atomic：单数据。

通常情况下同步使用官方提供的标准方案，不使用系统层面做同步，因为系统层面有系统调用的问题。在运行时层面包装也有很多的限制。我们使用 goroutine
模型标准做法倾向官方提供的一些解决方案。因为官方提供的解决方案和运行时协调始终会保证向下兼容。所以一般建议不要使用第三方框架做同步，因为多数情况下的性能问题是架构设计和核心算法，逻辑代码太烂也不至于产生瓶颈级别的问题。

通道基于设计层面或者架构层面，比如把逻辑拆分成生产、消费等不同角色，或者利用通道实现定义好的一些编排，比如同时处理文件从架构设计上使用通道处理考虑读取和处理分开提高它的效率。通道实际上使用的层面比较高，更倾向设计层面，相当于架构里面选择
Kafka 把它作为异步架构的中心，通过它来解除不同直连的操作。通道也有类似的角色，更倾向于拿它来编排、架构、设计层面做一些事情。

同步是为了保护某一段逻辑片段，同步是代码级别的保护，在并发时可能有一段逻辑同时执行，数据就有数据竞争效应。

原子操作操作的是数据，是某个内存地址里面的多大长度的片段，是整数还是其他类型。

所以这三种方式不存在替代效应，在不同场景选择合适的同步方式。通道适合在设计层面上，同步倾向逻辑片段的保护，原子操作倾向单数据处理。

### 通道与同步的意义

我们抛开分布式架构不说，现在就看当两个并发任务抢同一份数据时在内存同步上究竟怎么做。

比如说 G1、G2 同时共享一份数据，因为 G1、G2 完全可以在线程 T1、T2 上运行，而 T1、T2 完全是在两个核 Core1、Core2
上。它们可以同时执行，就会产生数据竞争 (DataRace)
效应，我们为了避免数据竞争所以对这些数据加锁，锁是一种令牌，谁拿到令牌谁执行，拿不到令牌就阻塞。

利用通道机制可以实现同步，通道本身可以编排多个并发任务，多个并发任务通过消息机制来进行控制。甚至可以把并发变成串行，但是它们是有差别的。

我们用一个例子来看通道机制和同步机制。比如公司有个项目需要两个团队来完成，一个团队在北京一个团队在上海，两个团队相对各自独立各自做各自的事，北京做后台，上海做前端，两边有一套沟通机制，但是大部分时间各自做各自的，需要的时候有沟通机制，可能是由特定的程序员或者
PM 沟通协调。

通道机制更多层面上是涉及到架构和逻辑体系上的协调。它的粒度非常的大，使用通道协调两个并发任务的时候，属于架构层面和逻辑层面的设计。不应该用通道控制对方。比如没有办法在北京协调上海团队日常开发一样，这种协调迟早会出问题。所谓的网络协作大多数不成熟，大多时候需要现场协调。远程管理成功的案例也非常少，往往要求所有成员的基础素质非常的高，说白了发送某条消息就能完全把所有的事情做完回馈
ok，如果能力不够，介入太深两个团队都会出现问题。只是协调两边机制或者两边 PM 在协调，不能透过对方的 PM
直接渗入对方的内部成员当中，这种架构设计肯定会出事。

比如内部同事之间借个东西，这个东西是内存中的数据，在非常短暂的时间之内独占内存不适合用通信，而是同步机制，小粒度的情况下，并不适合用通道机制。

比如北京团队内部同事之间借支笔，用完立刻还给对方，这是很简单很短暂的事情。现实中不能先向 PM 打报告然后由 PM 通知同事，PM
拿到同事的笔给你，你使用完再通过 PM 传回去，这样无论从效率上还是从实际操作上都不现实。所以通道机制对于这种场合显得有点官僚主义。

通道的 CSP
模型不是用来取代内存共享的，用通信代替内存共享前提是以并发任务为单位。依赖内存共享就依赖细节，我们要依赖抽象而不依赖细节，这是架构设计上的概念。什么时候选择合适的模型非常的重要。

借东西与团队无关，它指的是临时的动作或者中间很短暂的步骤，是细粒度微观上的，是基于语句层面上的，所以它最小的单位是语句而不是并发任务。

当北京团队向上海团队借东西的时候，这种逻辑设计本身就有问题，最好的设计是 PM 发现所有团队都有这个需求，PM
给每个团队复制一份数据。因为从使用角度来说从北京团队打断上海团队某个人拿到它的数据，数据由上海发到北京导致中间传输开销，同时上海团队因为没有数据一直等着北京使用完还回去，这就是设计上的不合理。这时作为正常的架构设计师考虑的是给每个团队复制数据，综合成本会小很多。复制传递的开销小于引用传递的开销。注意没有任何一种理论是通用的，任何一种理论必然有优点和缺点。

### 标准库：同步

通道 (channel) 并非用于取代锁(mutex)。

  * Mutex：互斥锁，不支持递归锁定。
  * RWMutex：读写锁，仅在写时独占。
  * Cond：单播、广播事件。
  * WaitGroup：等待计数器。
  * Once：单次执行。

平常开发中肯定会使用锁这样概念。锁有很多种，例如互斥锁(Mutex)、读写锁(RWMutex)、条件锁(Cond)、信号量(Semaphore)、自旋锁(SpinLock)、原子操作(Atomic)，最常见的有哪些锁呢？为了数据竞争我们需要加个锁，它们有不同的性能差别，也就意味着不同的锁适合用在不同的场合。任何时候锁的选择都会很性能有很大关系。

标准库提供一些方式，比如互斥锁设计的比较精巧，它在 runtime
层面提供了两种锁，内核使用一种更轻巧的锁，对外提供基于信号量设计的互斥锁，多数情况它的性能不存在问题。我们使用锁造成的问题不是锁本身有问题，多数情况下锁导致的性能问题是设计导致。比如很多时候锁本身可能会导致一些竞争，不同基数的请求抢这把锁带来的结果可能不一样，我们应该把锁的力度变得更小一点。读写锁读的时候没有锁这个概念，只有写的时候独占。Cond
不是当锁来用而是用来做广播。

我们开发一个项目时候，第一需求整理上用伪码标注出来，第二把核心的算法做一些原型进行测试。

### 信号量(Semaphore)

#### 介绍

信号量是用于控制并发的。锁是需要几个人激活，而信号量是限制并发的，信号量用来控制有多少个并发任务可以同时执行。例如把信号量设置成 3 意味着有 3
个并发单元可以同时工作，超过 3 个的等待，完成一个后激活一个等待。

说白了有些资源处理的能力有限，需要用一种方式控制最多同时能使用多少。现实场景类似停车场，停车场总容量是十辆车，超过十辆等待，出去一辆则进来一辆，但是总数控制在十辆。适用场景最常见的是
Web 请求，用信号量控制当前并发速率，即确保当前并发数量是一万个，超过一万个的就等待，避免数据库或者服务器被拖垮。

所以信号量是用锁控制并发的数量，超出某个阈值就等待，其中有任何一个释放信号量就可以补充，总共的并发总数限制。

信号量内部有计数器大于多少就有多少可以工作，等于零时等待。所有同步方式都基于信号量实现，使用运行时实现确保性能是最好的。

实现信号量最简单的方式就是设计一个通道。

    
    
    func sema() {sem := make(chan int, 3)
        sem <- 1
        sem <- 2
        sem <- 3
    }
    

这就相当于创建一间教室，教室有三个位置，用书包占位相当于占了一个信号，从教室出去的时候把书包取走就空出一个位置。很显然很容易实现一个信号量控制多少人同时进出。异步通道是有多少数据槽，数据槽占满需要等待。但是通道的粒度太糙，性能不好。所以在运行时并没有使用管道机制实现。它是用原子操作针对一个计数器操作。

原子操作本身是安全的，它只需要提供整形变量 x，设置初始化值比如 3，一旦拿走信号减一直到数字变成 0 时候，所有人都得等。当还回去时候数字加一。

#### sema.go 源码解读

#### 请求信号 semacquire 函数

请求信号量需要地址空间，操作的是变量需要这个变量地址。

请求数字减去一使用 `atomic.Cas(addr, v, v-1)` 返回剩余数量，用减法 0
本身是一个常态值。当然也可以加一，但是多数情况下信号量是初始化几个，请求一个减一个，零表示没有信号。如果用加就需要用 2
个值来表达，这是设计上常见的习惯。减去一返回成功就直接获取信号拿到了信号。

获取信号失败的情况有几种，一种情况计数器已经是
0，一种情况减去一失败，因为可能在同一时间有其他的并发单元抢先一步请求到信号。原子操作不能保证这些代码处于事务中，只能保证 `Cas` 函数是不可分割的。

获取不到信号时，它会把自己打包成很特殊的对象，这个对象存储这个操作数的地址，放入队列中。

这个队列使用类似字典原理地址当作主键保持这个队列，因为很多并发单元抢同一把锁，计数器的地址肯定是一样的。所以用地址当作主键可以保证抢同一把锁的并发单元放到同一个队列中，另外使用地址作为主键可以维护多个不同的锁。

接下来增加队列的等待计数器 `nwait`，目的是记录队列中有多少的并发单元在等待。

完成上一步时可能锁已经释放出来了，所以立即再做一次检查，因为抢到信号量可以立即退出。

这时把自己放到队列中等待直到唤醒，`goparkunlock(&root.lock, "semacquire", traceEvGoBlockSync,
4)` 语句就是把当前并发单元进入休眠状态，直到有人唤醒放到待运行队列中。

被唤醒后再次检查能不能抢到信号量，因为被唤醒也可能会失败，失败了继续循环。被唤醒只是有信号量，有其他并发单元可能提前抢到信号量。

#### 释放信号 semarelease 函数

请求信号是在等待计数器上增加计数，统计等待队列有多少并发任务在等待。释放时首先找到等待队列，然后释放信号。

实现检查队列中等待计数数量，最好的方式直接用计数器实现，因为单个数字可以用原子操作，列表、链表不能做原子操作，所以用整数型的计数器是最合理的。

如果等待数量不等于 0，则唤醒一并发单元，请求信号时休眠需要释放信号唤醒。

因为在你等待的时候，其他的人把剩下的人全部放掉了。因为执行一个锁操作要耗费大量的时间。

从链表结构队列弹出等待并发单元，等待计数器减一，弹出后立即锁放锁，因为弹出后和队列没有关系了，接下来的操作是针对并发单元，再占用锁不合理。尽可能快的归还锁也是系统代码必须做的事。

`readyWithTime`
函数是立即唤醒并发单元。即把并发单元重新放回待运行队列，，放回待运行队列依然处于排队状态，什么时候执行需要看调度器调度。唤醒的花费的代价比较大，因为休眠时需保存上下文，唤醒需恢复上下文。

#### 小结

系统代码和应用代码的思路差异非常大，因为系统代码不会轻易的把整个操作维持事务性，系统代码考虑不是一个并发单元，它考虑让任意并发单元尽快进入状态而不是让其中某一个并发单元进入状态，系统代码考虑的是大局层面，应用代码考虑的是对象层面，很多程序员也很容易陷入单对象的角度，缺乏大局观。

在系统设计的时候，尽可能缩小单个片段，用多个小片段叠加，两个片段之间的空隙时时刻刻需要做重复检查。系统设计应该用积极的态度去尝试能不能满足条件而不是被动的等待。

这种设计思路上的差异带来两种程序员对于事情考虑角度的差异。

### 互斥锁(Mutex)

#### 介绍

互斥就是每次仅允许一个并发单元操作，不区分读写操作。这个并发单元释放锁后其他并发单元才能拿到锁，否则都需要等待。

互斥操作有两种实现方式，一种是由内核实现的，一种是由运行时实现的。内核实现意味着阻塞的时候内核时间片会被拿走，运行时实现意味着执行序会被拿走。无论怎么实现都会涉及上下文切换，相对来说代价会比较大。

#### 互斥锁不支持递归锁

什么叫递归锁呢？比如线程 1 加锁，接下来再次在线程 1 上加锁可以么？

两个线程或者两个并发单元可能有数据竞争效应。一个线程内没有并发，线程内使用协程也是串行的。也就意味着线程已经拿到锁，再次加锁没有任何影响，因为锁的还是它自己，这种情况下叫做递归锁。注意递归锁加锁和解锁数量要完全配对。

    
    
    var m sync.Mutex
    
    func A() {m.Lock()
        defer m.Unlock()B()
    }
    func B() {m.Lock()
        defer m.Unlock()println("hello")
    }
    func main() {A()
    }
    

上面例子有一把锁，调用 A 加锁，调用 B 再次加锁，这涉及锁的递归调用。A 加锁 B 加锁 B 解锁 A
解锁，有些语言支持在单个线程上递归加锁，goroutine 可能被调度在多个线程上执行，所以互斥锁不支持递归加锁。

Go 语言互斥锁不支持递归锁。Go 语言的并发单元不是线程，是
goroutine，当并发单元拿到锁，它并不能绑定到某个固定的线程上，可能中途某种原因重新放回队列，被调度到另外线程上恢复执行，并发单元不能确保锁永远在单个线程上串行执行，实际是在不同线程之间转移。

互斥支持递归锁和语言实现有关系。比如 Java、C# 的并发单元是以线程为单位，支持递归锁。Rust
的并发单元和线程是一对一模型，永远绑定在一个线程上，也支持递归锁。Go 语言的并发单元可能在多个线程运行，不支持递归锁。

互斥仅能被一个对象拿到锁，如果不支持递归锁重复锁定就会造成死锁。所以选择锁需要慎重，支不支持递归？语言实现有哪些限制？否则很容易死锁。

通常情况下建议定义类型不要默认把它实现线程安全的，更倾向把这种安全机制交给用户来实现。对于标准类型来说，面向的是很小的粒度，只是提供代码级别的控制。线程安全提供的不是代码级别的控制，而是提供解决方案。

#### 实现思路

用什么思路设计一个互斥锁？

  * 拿不到锁需要阻塞，怎么阻塞？每隔 1 秒循环一次？
  * 阻塞一个线程或者一个并发单位它处于什么状态，是否会消耗时间片？
  * 使用什么机制判断拿不到锁？
  * 使用什么机制判断拿到锁？

简单的做法锁状态使用变量，0 没有锁 1 有锁，拿锁判断状态是 1 时阻塞等待变成 0。怎么等待？每隔 1 秒循环一次？很显然 1
秒粒度太大，循环操作一般会快速调用大量的 CPU 指令导致 CPU 占用率很高有性能消耗，而且会非常耗电。比如代码没有优化 CPU
满负荷的执行指令无限循环做加法。这些实现不是写几行代码就能搞定，而需要设计一种机制实现什么时候等待什么时候拿，同时不要让并发单元处于空耗状态。

最优的设计是并发单元不要重试，因为重试的时候根本不知道之前拿到锁的并发单元什么时候结束，应该在恰当的时候归还控制权和时间片，进入休眠状态。并发单元释放锁时候用消息通知的方式通知等待的并发单元从休眠状态重新激活。无论使用线程实现还是
goroutine 实现，在任何状态下休眠机制需要上下文切换，付出很大的代价。那么休眠机制使用什么方式比较合理？

休眠机制存在另外的问题，比如拿到锁的并发单元只执行 1
毫秒甚至更少就释放锁，这时候休眠机制非常浪费。函数调用使用回调是一种消息通知机制，但对于锁这种精巧设计来说使用回调粒度太粗。使用回调函数恢复到上次执行断点，从顺序执行状态变成异步执行状态导致执行序会很乱，锁的设计也不合适。设计锁需要在不同状态下进行调整。所以使用消息阻塞机制不用回调机制。

互斥锁有状态码用来处理计数的信号，状态码记录锁的内部状态，它是按照二进制位设计的，32 位整数，尽可能保证用一个寄存器完成数据操作，因为效率最高。使用 3
个部分用来标记，第 0 位表示是否锁定，第 1
位表示有没有正在观望处于清醒状态，这种清醒状态称之为自旋状态，剩下来的当计数器用来保存一共有多少人在等。等待的人有两种状态，一种是自旋状态，一种是休眠状态。从休眠状态唤醒需要花费很大代价。释放锁的情况下优先给自旋状态的并发单元，因为它的速度最快。

#### mutex.go 源码解读

##### 加锁 Lock 函数

首先尝试加锁，原子操作把第 0 位变为 1，如果锁没有并发单元使用就会立即返回。锁没有并发单元使用情况下，所有的状态都是
0，这是最理想的状态，因为一旦命中效率极高。它就是为了第一次加锁准备的，它不会一开始假设后面已经被占用。系统代码一切可能换取性能。

如果加锁不成功，首先使用变量保存老的状态值。然后检查一个准备替换的新状态，新状态和旧状态的差别就在第 0 位是否上锁，接下来判断第 0 位和第 1 位
and 操作是否不等于 0，如果等于 0 表示原来第 0 位也是 0，如果等于 1 表示锁已经被占用。

如果已经占用进入自旋状态，如果没有占用，再次尝试用新的状态代替旧状态。新旧状态差别就是第 0 位上锁。

如果已经上锁，这时候检查是否处于自旋状态，自旋状态就是不进入休眠，执行空循环，执行几条指令就再次检查。能进入自旋状态。它会在第 1
位加个标记，表示有并发单元正在门口转圈，如果有锁释放，应该优先拿锁。唤醒有两种机制，如果不加标记不知道有人转圈，这时候自旋，累加转几圈，自旋先设置清醒标记状态然后不停转圈，iter
记录转圈次数。

如果一直自旋的话，就一直累加计数器，累加计数器就是原来的值加上偏移量，我们知道第 2-30 位记录的是等待计数，第 2-30 位加 1 必然要跳过第 0
位和第 1 位，实现方式是第 2-30 位的值 x 加 1 左移 2 位(x+1<<2)，这样把 1 加到第 2 位。

累加计数器等于并发单元原来是自旋状态转为休眠状态，由于之前是自旋状态标记上清醒状态，需要把清醒标记清除掉(&^)，不然出现状态重复。

接下来再次判断能不能加锁成功，这时候有两种状态，计数器加 1 的状态写入，等待计数被修改。

这时候要判断有可能加锁成功的，也有可能加锁不成功，刚刚进入自旋状态走过来是没有成功的，还有一种状态是自旋退出找到锁的和一开始没有进入自旋状态的时候，那么在上面是已经加锁的，只不过自旋没有成功才会取消。

第一种可能修改等待数量，第二种可能修改第 0 位为 1。进入自旋状态进入休息室睡觉的，还有一种从一开始拿到锁的，所以修改状态的时候有两种可能。

第一种是原来没有锁现在有锁就退出，因为拿到锁了，第二种是原来有锁现在没有成功，则进入等待信号状态，可能进入休眠状态也可能进入自旋。

这时候看到了加锁操作的过程，最乐观状态立即拿到锁，如果拿不到进入循环，循环内部首先记录两种状态，原始状态 old 和加上锁的状态
new。第一个流程原始状态没有锁进入加锁状态。第二个流程原来原始状态有锁，进入自旋状态等待，自旋过程中标记上清醒标记 awoke，多次自旋累加自旋计数器
iter，continue
重新进入循环，再次判断原始状态有锁，再次进入自旋，直到自旋条件不满足的时候，因为任何自旋都是有限制的，要么是时间，要么是次数，这个实现是通过次数决定的。如果达到自旋次数没有等待锁就加到等待计数器里，然后清除清醒标记，如果修改状态不成功，等待信号直到有并发单元唤醒从休眠状态转为自旋状态。

##### 解锁 Unlock 函数

解锁操作首先把锁标记去掉，第 0 位从 1 改成 0 释放锁。

判断有没有并发单元再等待，等待有两种可能，计数器是否等于 0，自旋状态是否等于 0，如果都为 0 才能退出。

如果不为 0 肯定有并发单元再等待，释放锁需要唤醒信号量，sema 是等待队列唤醒通知。这时候必然有并发单元拿到锁，处在自旋状态的优先拿到。

基于某种计数实现是否自旋。

执行自旋操作，是由汇编代码实现的，用 AX 保存计数器，默认 30，把 AX 每次减去一，执行 30 次循环，`PAUSE` 指令是 CPU
专门设计的，告诉 CPU 接下来循环等待，空耗，CPU 看到这个指令后会进行优化，比如用低功耗方式运行，避免占用大量
CPU。那么所谓的自旋就是用低功耗方式做 30 次减法。

### 读写锁(RWMutex)

什么情况下才会产生数据竞争，比如同时看一本书有数据竞争么？看的情况下肯定没有数据竞争，因为不修改数据，同时读数据而不改变数据的时候不会产生数据竞争效应。什么情况下有数据竞争效应呢？两个并发单元都写或者一个读一个写才会产生竞争，所以读写锁是为了改善互斥锁的缺点。

互斥锁的缺点是它不区分读写操作，比如多个并发单元同时读取数据即使不修改数据也要排队，并发就变成串行了。而读写锁，同时读数据不需要加锁不阻塞。当修改数据需要确保所有并发单元修改都是同步的，需要独占锁，所有并发单元都等待阻塞。所以读写锁对读并发做优化，读写锁算是互斥锁的一种改造版本，它在一定程度上能提升这种互斥锁的性能，因为互斥锁对于读并发也变成串行。对于有大量的客户端读数据很少修改数据的场景，用读写锁可以在很大程度上提高性能。

读写锁的特点是多个并发单元读取数据不会阻塞，因为数据的状态是稳定的，只有修改数据才发生阻塞锁定。它对于读大于写的场景很容易提升性能，因为它减少了锁的次数。

#### 代码实例

    
    
    func rw() {
        var wg sync.WaitGroup
        var rw sync.RWMutex
    
        for i := 0; i < 4; i++ {wg.Add(1)
    
            go func(id int) {defer wg.Done()
    
                lock, unlock := rw.RLock, rw.RUnlock
                if id == 0 {lock, unlock = rw.Lock, rw.Unlock}
    
                for i := 0; i < 10; i++ {lock()
    
                    fmt.Println(id, ":", time.Now())
                    time.Sleep(time.Second * 3)
    
                    unlock()}}(i)
        }
        wg.Wait()}
    

#### 实现原理

读写锁实现比普通互斥锁复杂的多，它要面对不同的状态。读写锁内部有两个信号量，一个是写信号量 `writerSem`，一个读信号量
`readerSem`，读写锁在写操作时候写操作是互斥的，任何时候只有一个写操作，写操作和读操作不能同时进行。读操作相互之间没有影响，可以并发。所以读操作和写操作使用不同的信号量。另外有两个读计数器，当前所有读用户的总数
`readerCount` 和等待用户的总数 `readerWait`。

### 源码解读

#### RLock

读操作加锁非常简单，就是把读计数器 `readerCount` 加 1。因为读操作之间没有影响，每个人保证是一样的。

读计数器加 1，如果读操作计数是很大的负数结果肯定小于 0，小于 0 就是有写操作，不能读操作。通过判断是否小于 0
可以判断是否有写操作正在进行，通过读操作信号量休眠。

#### RUnlock

在写操作之前有读操作情况下释放锁读计数器减 1。如果写操作正在进行计数器数字就很小，所以通过负数判断正在写操作进行。

写操作休眠之前有多少读操作把正在进行的等待计数器减 1，所以读操作再释放时必须把这个计数器减掉，减掉为 0 为止，通过写操作信号量唤醒。

写操作要等待当前所有读操作完成才能进行，`readerWait`
记录了当前有多少个读操作正在进行，所有读操作退出的时候都会减去这个数字，减到为零的时候把写操作唤醒，这样就能进行写操作。

所以我们注意到有两个计数器，读操作计数器通过把它变成一个负值让读操作可以判断出当前写操作是否在进行，`readerWait`
记录的是写操作开始之前有哪些读操作正在进行。

#### Lock

写操作首先有把独占锁 `w`，因为两个写操作不能并发，必须使用锁实现多个写操作之前阻塞，来保证两个写操作同一时刻只有一个能进行。

接下来把读操作总数减去常量值 `1<<30`，读操作总数就变成很大的负数，但是返回结果再加上常量
`1<<30`。所以这一行做两件事，第一返回读操作总数，第二把读操作总数设置成很大的负数。

取到有多少读操作正在进行后，把它写到读等待计数器 `readerWait`
中，写操作必须要等待所有的读操作结束，读操作没有完成之前不能写操作。所以必须进入休眠状态等待被唤醒，即等到所有读操作完成。

#### Unlock

写操作结束时，首先恢复写操作计数，恢复之后就得到当前多少读操作在等待，读操作一种是已经结束的，一种是还有写操作进来的，使用读操作信号唤醒所有读操作，恢复所有的读操作。

#### 小结

`w` 是多个写操作互斥锁，或者同一时刻只有一个写操作，`writerSem` 是写操作休眠唤醒信号量。`readerSem`
是读操作休眠唤醒信号量。`readerCount` 是所有读操作的计数器。`readerWait` 在写操作之前当前有哪些读操作正在进行，只有等待计数器为
0 写操作才能启动。所以两个计数器的作用不同。

同时利用巧妙的做法 `readerCount` 减去固定的值使它变成一个负数来通知所有打算进入读操作的并发单元，现在有写操作准备进行需要等待。

我们发觉原子操作只能在原子操作本身上实现事务，因为跨语句以外不能保证。所以利用负值状态利用原子操作这种特性同时产生这种通知效应。用其他的东西就需要加锁同步，所以这是一种很巧妙的设计。

利用原子操作特性利用负值实现通知效应，用两个信号量用两个计数器就可以实现读写操作编排，写操作必须等读操作结束，读操作可以并发，写操作完成后要唤醒所有读操作，另外多个写操作必须是互斥的。

读写操作只是利用了信号量和计数器来编排操作，读写锁本身是利用编排，实际上读写锁真正读的是让写操作互斥，其他时候更多的是编排读写操作顺序。

### WaitGroup

WaitGroup 通过状态值和信号量，增加的时候调整计数器，12 字节数组存储状态，然后分为高低表达不同的状态。

增加的时候把高位计数器增加。高位计数器用来判断加的值，低位计数器用来判断有多少人等。

Wait 操作类似用自旋的状态，把状态读出来判断是否为 0，为 0 就退出，不为 0 就进入休眠，休眠在执行减法的时候唤醒。

WaitGroup
一旦被拷贝时候会出现问题，在两个不同对象上等结果肯定不同，所以有种机制发觉防止拷贝了。比如一个结构体，防止自己被复制，用一个字段把自己的地址写进来，如果被复制了以后地址就不相等了，因为新的地址和字段存的地址肯定不等，这样就知道是不是被复制过。

### 条件锁(Cond)

条件锁是基于锁的基础之上实现一个信号通知。普通的锁是拿到锁，释放锁时其他并发单元才解除阻塞。如果多个并发单元竞争一把锁，暂时不释放锁，中途给其他并发单元发送一个信号，这个信号有两种激活方式，第一种方式是让其中一个并发单元激活，第二种方式发送广播信号让所有并发单元激活。这是锁的另外一种应用，利用锁来实现消息事件通知的功能，让其中一个并发单元激活或者同时广播让所有并发单元激活。

这种场景很常见，比如有个通道，写操作使用批操作一次性写入 1000
条数据，有很多并发单元读数据。使用不同的方式通知，一是有次序的数据，每次唤醒其中一个读操作，第二种激活所有读操作。

#### 代码实例

下面例子创建一个条件对象 `c`，这个条件对象必须初始化锁，它内部要依赖这个锁，然后创建 5
个并发单元，每个并发单元上锁等待通知，有信号执行操作再释放锁。有两种通知方式，一种是通知其中一个并发单元，一种是用广播通知所有人。在另外一个并发单元一秒后执行单播，两秒后执行广播。

    
    
    func cond() {
        var wg sync.WaitGroup
        var c = sync.NewCond(&sync.Mutex{})
    
        for i := 0; i < 5; i++ {wg.Add(1)
    
            go func(id int) {defer wg.Done()
    
                c.L.Lock()c.Wait()
                fmt.Println(id, "done.")
    
                c.L.Unlock()}(i)
        }
    
        go func() {time.Sleep(time.Second)
            c.Signal()time.Sleep(time.Second * 2)
            c.Broadcast()}()
    
        wg.Wait()}
    

这是很简单的通知机制，利用条件锁在不同并发单元之间协调，相比通道性能更好一点。

#### 实现原理

条件锁的内部依赖锁和通知列表。

`Wait` 操作先把自己加到通知等待队列中，接下来立即解锁. 所以示例中在 `c.Wait()` 之前先加锁 `c.L.Lock()`，然后执行
`c.Wait()` 操作时已经上锁，就可以把自己安全的加到通知等待队列中，接下来立即释放锁，所以执行完 `c.Wait()`
语句时，它已经把锁释放了，然后阻塞等待通知，通知立即上锁，上锁以后才能安全的执行并发任务，然后解锁。

示例中我们认为 `c.L.Lock()` 和 `c.L.Unlock()` 是配对的，其实不然，严格来说分解 `c.Wait()`
语句是加到队列中，解锁，休眠直到被唤醒，然后立即执行加锁操作。示例中加锁的目的是为了能够安全的加到等待队列中，然后内部解锁，被唤醒后需要保证语句执行是安全所以加锁，最后释放锁。

所以我们使用条件锁要非常小心。`c.L.Unlock()` 写在 `fmt.Println(id, "done.")` 上面和下面完全不同。写在下面意味着
5 个并发单元构成锁的同步，所有的并发单元使用的是同一把锁串行执行 `fmt.Println(id, "done.")`。

Signal 和 Broadcast 操作很简单，就是调用通知一个和通知所有的方法。

通知列表内部使用链表实现，加到等待列表休眠累加计数器表示有多少人等待。后面加前面出，如果追平则表示没有等待，自增序号不停的加减，这种实现可以保证等待计数，顺序是有序的。

通知单次操作会检查序号，而不是在链表里随机唤醒。广播操作遍历整个链表。现实场景银行取号，排队叫号直到和你相等的时候你才进行。

所以 `Wait()`
操作首先拿到序号，然后放到等待队列中，序号就是累加计数器，在等待队列中需要持有这个序号，因为接下来与这个序号有关系。如果等待序号和通知序号相同表示没有等待的并发单元。广播通知会设置为相同。

### Once

Once 保证函数只执行一次。比如做 Orm 时候可能会启动多个并发任务创建连接，在每个地方都有责任去判断当前数据表是否存在，不存在则需要创建表。

    
    
    func do() {f := func() {fmt.Println(time.Now())
        }
    
        var once sync.Once
    
        for i := 0; i < 5; i++ {once.Do(f) //f 函数只执行一次
            // f()// f = func() {//     fmt.Println("hello world!")
            // }
        }
    }
    

上面 `f` 函数虽然循环 5 次，但是只执行一次而且是并发安全的，可以在多个地方执行。所以用 Once 执行初始化操作非常合适。

Once 内部有个锁和状态值，首先判断状态值是否为 0，不为 0
表示已经执行过不执行了，用原子操作保证并发安全。如果没有执行需要加锁来阻止执行期间并发执行，必须保证有多个并发的情况下只有一个可以执行。加锁后判断状态值为
0，再执行函数，函数执行结束把状态值变为 1。

假设 A 和 B 同时执行 Do，Once 使用两次判断，A 先拿到锁，B 尝试拿锁不成功处于等待状态，A 执行 f 函数，然后把状态码设为
1，然后释放锁，使用 defer 可以保证肯定能执行。B 得到锁，判断状态码是否等于 0，释放锁，所以并发的二次检查是非常重要的。

### 自旋锁(SpinLock)

自旋锁和互斥锁非常像。

它们的区别是时间片的影响。比如互斥操作阻塞，除非拿到锁拿不到就阻塞，这个时候通常情况操作系统或者运行时会把剩下来的时间片拿走，用来执行另外一个并发单元。

互斥锁造成阻塞，如果是操作系统实现的内核互斥对象，操作系统会把剩下的时间片拿走，如果运行时实现的，运行时会把剩下的时间片拿走，可能 M/P
组合去执行另外一个任务。所以互斥锁的粒度相对来说比较大，因为下次拿到锁的时候是由操作系统内核或者运行时通知，重新分配时间片去激活。

有些时候我们需要做很短的时间锁定，比如只是做很简单的原子操作，或者一个请求逻辑很快返回，没有必要交出时间片，因为交出时间片要做调度甚至上下文切换，这种代价很大。那怎么设计？可以设计循环不停的去检查，如果
OK 就跳出循环继续执行，如果没有 OK 就继续循环，这个时间很短就能返回，不需要做控制权的移交，也不需要做上下文切换。

自旋锁用来快速锁定，否则的话不但会浪费时间片而且会把 CPU 跑满，因为不停的做循环，这个循环非常的快，内部就是简单的判断指令很容易 CPU
跑满，而是时间太长可能其它的并发单元会被饿死掉。所以自旋锁是用来处理极短时间之内的这种锁定，它的好处是不需要让出时间片不需要做上下文切换。

对于极短时间内的自旋锁操作，不用交出时间片没有上下文切换，所以它的效率会很高。但是使用循环会消耗很高的 CPU
资源，时间非常长会导致很严重的问题。选择互斥锁还是选择自旋锁完全看算法侧重于哪个方面。

### 原子操作(Atomic)

原子操作是用来控制内存操作的事务性。原子操作最常见的做法是用 CAS。用原子操作可以实现 Lock-free，就是所谓的无锁并发。

原子操作是在汇编层面上实现的，或者说是由 CPU 指令来实现的。它的好处是实现类似 lock-free
就是说不用显式的加锁就能保证对多个并发对同一份数据操作的安全性。

#### 单核和多核指令是否原子

原子操作是不可分割的操作，高级语言的单条语句不一定是原子操作。简单的变量赋值都不能不可分割的，因为从汇编上它会翻译成好几条语句。那么单条汇编指令是不是原子操作？

![](https://images.gitbook.cn/n04QSe)

CPU 通过三条总线地址总线、控制总线、数据总线完成一条指令。

如果单核的话，单条汇编指令肯定是原子操作，因为操作系统对于时间片的调度肯定不能打断单个 CPU
的指令，因为调度本身也是基于函数来实现的，它不可能把一个汇编指令打乱掉，所以在单核上一条汇编指令可以确保是原子操作。

如果多核的话，单条指令不能保证是原子操作。由于多核是并行执行，数据被修改可能打断一条汇编指令的操作，数据被改变了中途肯定被其它的核打断了。比如地址总线和控制总线执行完成，数据总线执行时另一个核修改了数据。现在所有的
CPU 都是多核的，在多核的情况下很复杂。而且现在编程语言不能控制底层，离汇编越来越远。

#### 如何实现原子操作

如何保证单条汇编指令是原子操作？CPU 总线上有根 HLOCK pin 引线用来执行 `lock` 指令。当汇编指令前面加上 `lock` 指令 CPU
会把这条线的电位拉低，拉低后 CPU 会把地址总线锁上，因为地址总线被锁上，其它的核操作需要等待地址总线放开，所以使用 `lock` 指令 CPU
就完整执行变成原子操作，可以确保这条指令不会被其它核打断。所以这是在多核情况下实现汇编指令或者机器指令进行原子级别的操作。原子操作实际上是在很极短的生命周期让
CPU 并行失效。所以有些文章中会建议慎重使用原子操作。因为多核锁定造成并行变成串行使用不好反而降低执行性能。

原子操作只能保证一条汇编指令是原子操作，不能保证多条汇编指令形成事务。因为只能锁定单条汇编指令，两条汇编指令之间依然会有其它的核介入。

所以原子操作不能替代互斥锁。互斥锁可以保证事务，可以保证完整块的逻辑，原子操作只能保证一条汇编指令的完整性。

#### CAS(Compare-and-swap)

我们可以利用原子操作 CAS(Compare-and-swap)特性实现 `lock-free` 的功能。CAS
实现方式很简单，比如有一块内存，内存保存的数据是 5，CAS
需要三个参数，第一个参数是这个内存的地址代表操作谁，第二个参数是旧值，这个值用来做检查和内存的值进行比较，如果两个值相等就用第三个参数值交换。所以 CAS
完整的意思是先比较然后交换。CAS 在不同的 CPU 指令集对应不同的汇编指令，在 Intel 中使用 `XCHG` 指令或者 `CMPXCHG` 指令实现
CAS 操作。

比如用 CAS 实现无锁的链表。先把链表挂到加进来的数据上，第二步判断 A 是不是头部，是的话交换 D。

    
    
    type Node struct {
        next  unsafe.Pointer
        value int
    }
    
    // 注意：并演示代码并未处理 ABA，并未实现 Double-CAS。
    // 可将 指针 + 计数器（版本号）作为条件。
    
    /*
        ABA 问题示例一：
    
        +-----+-----+-----+
        |  A  |  B  |  C  |
        +-----+-----+-----+
    
        G1 pop: old = A,  ....................................................  Compare(, A, B)  =>  [B, C]
        G2                  pop(A), pop(B), push(D), push(A) => [A, D, C]
    */
    
    type List struct {head unsafe.Pointer}
    
    func (l *List) Push(n *Node) {
        for {
            // 读取链表头，并将其挂到 n 后面。
            // 此时并未修改原链表，所以此操作不存在竞争。
            old := atomic.LoadPointer(&l.head)
            n.next = old
    
            // 尝试将 n 写到 head。
            // 会判断 old 是否还是上面读取的那个，如果是，那么就没有被其他人修改，可以写入。
            // 如果不是，那么表示中途被其他人修改过，此次操作放弃，重新循环。
            if atomic.CompareAndSwapPointer(&l.head, old, unsafe.Pointer(n)) {return}
        }
    }
    
    func (l *List) Pop() *Node { // 为什么不用 error？
        for {
            // 读取头，如果为空，直接返回。
            old := atomic.LoadPointer(&l.head)
            if old == nil {return nil}
    
            // 将 head.next 读出来。
            n := (*Node)(old).next
    
            // 如果能成功将 next 替换掉，那么表示中途无人修改过。
            // 如果替换失败，则需要重新循环，重新获取被人修改过的头。
            if atomic.CompareAndSwapPointer(&l.head, old, n) {return (*Node)(old)
            }
        }
    }
    
    // go run -race
    func main() {
        var wg sync.WaitGroup
        wg.Add(2)
    
        var list List
    
        go func() {defer wg.Done()
            for i := 0; i < 10000; i++ {list.Push(&Node{value: i})
            }
        }()go func() {defer wg.Done()
            for i := 0; i < 10000; i++ {_ = list.Pop()
            }
        }()wg.Wait()
    }
    

CAS 有个问题是 ABA 的问题，只比较一个值，并不能保证后面的逻辑是不是合法的，为了避免这个问题需要增加版本号。

#### 无锁结构建议

无锁结构 (lock-free) 基于原子 (atomic) 操作实现。

  * 优先选择 Mutex 实现。
  * 在调试通过后，可尝试用无锁结构改善性能。
  * 原子操作不适用所有场合。
  * 原子操作导致逻辑复杂度提升。
  * 优先选择成熟、完善的第三方库。

无锁结构建议不要使用，只要涉及并发就不存在真正意义上的无锁，原子操作也会有锁。区别在于原子操作由硬件处理。原子操作是针对单个数据的，在单个数据同步的情况下让一段逻辑同步需要做大量的类似循环的重试。单个原子操作作为条件涉及到类似于
ABA 问题。不建议用原子操作控制一段逻辑的同步。官方也要提到，它是一种非常底层的结构，不建议直接使用，它对于代码的控制能力要求非常的高。

#### 用原子操作实现自旋锁

Go 语言运行时自旋锁使用循环实现的，我们也可以用原子操作自己实现自旋锁逻辑。

    
    
    type SpinLock struct {state int64}
    
    func (s *SpinLock) Lock() {
        for {if atomic.CompareAndSwapInt64(&s.state, 0, 1) {return}
    
            runtime.Gosched()}}
    
    func (s *SpinLock) Unlock() {if !atomic.CompareAndSwapInt64(&s.state, 1, 0) {panic("unlock of unlocked spinlock")
        }
    }
    
    // go run -race
    func main() {
        var wg sync.WaitGroup
        wg.Add(3)
    
        var spin SpinLock
    
        x := 0
    
        inc := func() {defer wg.Done()
    
            spin.Lock()defer spin.Unlock()
    
            for i := 0; i < 10; i++ {x++}
        }
    
        for n := 0; n < 3; n++ {go inc()
        }
    
        wg.Wait()}
    

### 对比通道、互斥锁、原子操作实现并发安全的计数器

    
    
    func chanCounter() chan int {c := make(chan int)
        go func() {
            for x := 1; ; x++ {c <- x}
        }()return c}
    
    func mutexCounter()func() int {
        var m sync.Mutex
        var x int
    
        return func()(n int) {m.Lock()
            x++
            n = x
            m.Unlock()return}
    }
    
    func atomicCounter()func() int {
        var x int64
    
        return func() int {return int(atomic.AddInt64(&x, 1))
        }
    }
    
    func main() {f := mutexCounter()
        for i := 0; i < 10; i++ {println(f())
        }
    }
    

性能对比

    
    
    go test -v -bench . -benchmem
    BenchmarkChanCounter-8       5000000         234 ns/op          0 B/op        0 allocs/op
    BenchmarkMutexCounter-8    100000000         22.3 ns/op         0 B/op        0 allocs/op
    BenchmarkAtomicCounter-8   200000000         8.96 ns/op         0 B/op        0 allocs/op
    

原子操作很多时候有很好的性能表现。用通道方式，性能消耗很多。用互斥锁和原子操作性能差异并不大，互斥锁本身就是原子实现。原子操作是单个数据，只是单条指令，最多可以实现数据交换，并不具备多条指令中间的事务。互斥锁加锁和解锁中间过程是事务性的，可以确保处理过程不会被打断。

如果说通道适用于结构层面解耦，那么互斥锁则适合保护语句级别的数据安全。至于原子操作，虽然也可实现 `lock-free` 结构，但处理起来要复杂得多（比如
ABA 等问题），也未必就比互斥锁快很多。还有 `sync.Mutex` 没有使用内核实现，直接在用户空间以原子操作完成，因为 runtime
没有任何理由将剩余 CPU 时间片还给内核。

### 小结

锁比较复杂，甚至有各种各样的锁，更多的是在上面锁之上进行更多的整合、组合或者是变形来实现在不同的算法需求下进行数据竞争的保护，很多时候我们在数据结构里面发现同时使用多把锁，比如
pipe 会使用三把锁和两个 Cond。锁除了用来保护数据以外，通常还用来控制逻辑的执行。

我们对锁的使用非常复杂，甚至锁的组合使用有很多种变形，这需要我们平时做大量的练习。任何锁的使用都会影响性能，如果选错的话影响会很大的。

