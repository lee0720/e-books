---
html:
  embed_local_images: false
  embed_svg: true
  offline: false
  toc: true
print_background: false
export_on_save:
  html: true
  puppeteer: true
---
### IO 操作

我们在类 Unix 系统下大多数都是 IO 操作，比如 web 应用、数据库操作、文件读写，Linux 核心思想是把一切当作文件。

IO 操作一般分为两套，一套是操作系统提供的系统 IO，一套是标准库提供的缓冲 IO。

IO 操作不仅仅是读写数据，它提供的是所谓数据流的概念。不要提到 IO
就想到读写文件，很多东西都可以流化，它更像一种设计模式或者模型。数据流的核心是连续性的数据，数据流有的是提供好的，有的是陆续提供的。比如文件是提供好的，读取网络数据是陆续提供的。数据流是有顺序的，当前操作的位置通常称为读写位置或者偏移量。

数据流是可以嵌套的。数据流是生产线上的一系列连续型数据，数据经过不同的加工流水线工位处理。比如把数据流写到文件中，数据流会经过不同的工位进行处理，加密、压缩、用户缓冲
IO、系统 IO 等最后存到文件，读取数据使用相反的方向把数据还原。

换句话说 IO 操作是所谓数据流和工位的概念。

#### 标准库对于 IO 基本操作是什么

大部分语言和标准库里 IO 操作都是非常核心的内容，IO 操作给我们带来很多相关性的扩展。标准库 IO
包抽象一系列的接口，这些接口定义一系列的扩展，有很多不同实现，有标准 IO 操作、有缓冲 IO 操作、网络操作、压缩操作、加密操作。我们把 IO
接口梳理出来的好处是组装一条流水线就知道哪些接口可以放到这个流水线上。

标准库在接口设计上定义了一些最基本的接口类型，这些接口类型只有单个方法，读、写、关闭最基本一种操作。设计的基本原则是接口粒度最小化，如果需要复杂的接口可以把小接口组合起来。为什么提供基本接口？比如接口只提供读操作，这样除了读操作之外其他操作看不到也不需要看到，对于实现方来说它可以通过简单的扩展就能实现这个接口，如果接口定义有读写关闭就都要实现，对于实现方也是个负担。我们只依赖于我们需要的东西，不需要的东西不要依赖。

除了基本的接口类型以外，还有位置相关的、字节相关的接口类型，当需要复杂的接口的时候，比如把读操作和关闭操作组合成一个新的接口，读操作结束后把相关资源释放，需要提供关闭操作。从某个位置开始读取数据，需要提供定位到某个位置操作。

我们不建议设计一个非常复杂的类。比如有普通用户和内部用户，普通用户能够看到内部用户定义的接口，普通用户不小心使用了本不该使用接口会很危险，对普通用户来说也增加了学习和维护成本。对于实现方来说暴露一些本不该暴露的功能。在设计中最小化理念是不要让用户看到不该看到的东西。

标准库的设计是把我们最常见的各种场景组合起来，使用多个简单的接口组合成一个复杂的接口，从接口定义名称就知道有哪几个简单接口组成。提供接口定义不需要提供具体的方法，因为把接口匿名嵌入就拥有了它对应的方法。当我们设计的时候，每一个小的接口尽可能的简单，然后用尽可能简单的接口去组合成一个复杂的接口。尽可能用接口隔离用户看不到的实现，用接口隔离。

#### IO 操作基本概念

Go 语言中 os 包负责基本的文件读写，os 包是对系统 IO
的直接包装，所有的操作都会系统调用，任何时候尽量不要使用系统调用。所以当学习语言的时候，标准库可能会提供几套 IO 体系，我们需要搞清楚每套 IO
体系内部用什么实现的。

为什么会有系统 IO 和用户 IO 两层定义呢？首先，缓存无处不在，抛开 CPU 相关缓存，IO
相关缓存有哪些呢？操作系统向硬盘写数据操作非常慢，所以操作系统在内核空间为每个打开的文件包括 socket
提供系统缓冲区，无论单个进程还是多个进程，文件所有操作尽可能放到缓冲区处理。缓存常见理念是把单次操作变成批操作。操作系统在内核空间提供缓冲区，写文件先写到缓冲区可能没写到硬盘，读文件优先从缓冲区读，这样效率会很高。但是这个缓冲区在内核空间，内核空间操作应用程序进入内核态都会涉及上下文切换。

在内核空间之上，大部分标准库都会在用户空间实现一套缓冲
IO。用户空间不需要进入内核空间，不需要上下文切换。当用户空间缓冲区填满后会刷到系统缓冲区中，把多次操作变成一次批操作。当进程退出由操作系统使用同步方式或者主动调用刷方法把数据刷到硬盘上。内核空间缓冲区是为了减少向硬盘刷数据的次数，用户空间缓冲区是为了减少向内核空间切换时的上下文消耗，因为减少上下文操作是性能提升的关键。

在网络操作时有所谓零拷贝的概念。两种技术可以实现零拷贝机制。从网卡进来的数据首先会被放到操作系统缓冲区，如果用户空间要操作这些数据需要把数据复制到用户空间，这时候就有一次复制过程。有些特殊的场合可以避免这种复制，比如设计代理服务器，系统空间的数据交换到代理服务器用户空间处理，代理服务器处理的数据只需要解析头信息，大量正文数据不需要处理。常见做法是从头信息读取正文数据长度，利用系统调用
`SendFile` 在操作系统缓冲区只读出很小一段头信息，大量正文数据直接关联到出口，这个出口可能也是网络 IO 操作。因为操作系统内核为每个
socket
提供一个文件句柄，我们把正文数据和下一个要转发到后端服务器的文件句柄连接起来，这样这两个数据在内核空间直接交换不需要复制到用户空间，即使复制到用户空间也是很小的一段数据，甚至完全不复制。

操作 IO 需要搞清楚哪些数据需要操作，哪些数据不需要操作。Http 协议本身也是流数据，Http
协议包含头信息和主体数据，首先拿到头信息，头信息有相应的终止符，然后再读取相应的主体数据，把头数据复制到用户空间，主体数据通过内核直接交换。当然需要处理主体数据就需要复制，至于复制多少和协议有关。

现在还有另外一个技术把内核数据的内存直接映射到用户空间避免复制，只是读数据不修改数据的情况下可直接把这段内存映射到用户空间，在用户空间读取头信息性能会高很多。任何情况下大量复制数据都会带来性能消耗，建议减少操作系统内核空间的数据复制到用户空间的次数。

有些人使用 Go 语言写代理服务器就觉得性能比较差，其实就是先把数据从系统空间到用户空间，操作完再把数据从用户空间复制到系统空间，频繁的交换造成大量的 IO
操作。

#### IO 接口设计

IO 接口设计的理念是用接口实现最简单的操作，再组合成复杂的功能。除了基本 IO 操作，标准库还定义了一些组合接口用于一些限制功能。

`LimitedReader` 读写器用来限制最多读多少字节。比如把它嵌套在 Http
协议上，可以限制只读取头信息不读取主体数据。它的实现非常简单，内部有个计数器 `N` 用于统计读取多少数据，超出限制范围直接返回结束标记。

`TeeReader` 构建管道，读出来数据立即交换，类似命名行命令把读出来的数据写到另外一个读写器中。比如日志信息利用读操作把数据输出到屏幕上，同时输出到
w 把数据写到文件。Unix 的设计思想就是把所有的东西当作文件，用一些小的命令组合成一个复杂的操作，每个命令尽可能保持简单。它的实现非常简单，先使用
Read 读取一批数据，判断读出来数据长度是否大于 0，大于 0 则写到另一个 w 中直接返回，形成管道效应和组合效应。在流操作中就是数据和工位，Tee
类似一个工位，这个工位有读写两个角色。

`SectionReader` 在流上设置一个片段，只能在片段内进行操作。实现原理就是检查开始结束位置。

`MultiReader` 把多个读操作合并，按顺序去读。有时需要从多个文件中读数据，这些文件可能是动态的，比如 `tail -f file`
命令是文件被刷新后会同步输出，也就是命令打开后这个命令会阻塞等待新的数据。如果同时监控多个文件就可以使用 MultiReader 操作。

`MultiWriter` 把多个写操作组合起来。比如有多个文件做备份，用户不直接写多个文件，这对用户增加或减少文件也很麻烦。最好方式提供
MultiWriter 包装，用户只需要调用写操作，MultiWriter
内部处理分发操作，这是很常见的设计模型，看上去像负载平衡或者分发器的概念。实现原理是用户调用
Writer，它在内部执行一个循环同时写到多个后端，用户只写一次，执行多次分发。

#### 小结

IO
接口的设计的理念就是用简单的接口实现最简单的逻辑，然后根据需要通过组合叠加的方式实现一些复杂的应用。设计接口时需考虑接口是不是有污染、设计粒度是否最合理。

用不同的操作嵌套实现隐藏细节的一些操作，而不是增加一个新的方法来实现，比如 LimitedReader
通过一个接口包装来限制而不是通过增加新的方法来实现。这也是设计上的常见的思路。

### bufio

了解 io 设计思路后，用一个基本例子看下用户空间的缓冲 IO 怎么设计的？

缓冲 IO 是系统空间或者用户空间缓冲区，所有 IO 操作经过缓冲区把单次操作变成批操作，减少系统调用提升性能。系统空间的缓冲 IO
能确保所有进程数据是一致的，比如多个进程同时操作同一个文件，一个进程写入数据另外一个进程立即会读到新数据，因为多进程之间共享的是系统空间缓冲区。如果是用户空间缓冲区，一个进程修改数据另外一个进程读取不到，除非数据刷到系统缓冲区，因为每个进程有不同的用户空间，它们的内存没有交叠。

当一个进程写入的数据被另一个进程使用，第一种方式用系统 IO，第二种方式进程每次操作之后立即把数据刷到操作系统
IO，需要看刷的机制，是每次操作刷一次，还是多次操作刷一次，如果每次操作刷一次则用户空间缓冲 IO 显得有点多余，建议直接调用操作系统的系统
IO，所以选择哪个层面的 IO 和需求有关。

在标准库中 `bufio` 包提供用户空间的缓冲 IO 操作，它实现 Reader 和 Writer 接口所有的功能。

#### Reader

`Reader` 结构体有个缓冲区 `buf`，这个缓冲区在用户空间，它内部还有很多计数器。

常量阈值 `minReadBufferSize` 定义每次读 buf 最小缓冲区大小，`defaultBufSize`
定义默认情况下缓冲区大小。通常情况下缓冲区大小和系统页大小相同，因为操作系统以页为单位管理内存，大小相同写满后刷到操作系统内存利用率最优，操作系统可以标注这个页是被修改过的还是没有修改过的。默认情况下缓冲区大小是以页为单位，也可以调用
`NewReaderSize()` 自己定义。

缓冲区大小需要根据读写操作测试选择合适的大小。提交时如果缓冲区非常小会大量交换导致缓存没有意义，如果缓冲区非常大提交操作会变得复杂，缓冲区很多数据不会很快被读取也会导致内存浪费严重。当物理内存消耗非常大，操作系统会频繁换入换出也会导致整个系统性能降低。

`NewReaderSize` 读的 IO 数据可能是裸文件也可能是已经打开的 Reader。处于第一个位置工位肯定是裸文件，之后位置是包装过的
Reader，所以先判断 `rd` 是否已经是缓冲 IO，如果是缓冲 IO 并且缓冲区比设置的大就直接用传入的 Reader
没必要再包一层，这是很简单的检查措施。

`Reader`
结构体所有的操作围绕着用户空间缓冲区，用户空间缓冲区数据提交到操作系统缓冲区。缓冲区是个数组，数组的读写操作需要读位置和写位置来确定读到哪个位置、写到哪个位置，通过这两个位置也可以判断数组中哪些数据已经读过的、哪些数据是未读的。

##### Read 操作

`Read` 操作的参数容器使用的是切片，切片有长度和容量两个属性，它是按照长度判断每次最多从 Reader
读取字节数。所以首先判断传递切片参数的长度是多少，如果为 0 就没有必要读。

    
    
    func main() {f, _ := os.Open("main.go") // 用操作系统提供 IO 打开一个文件
        defer f.Close()r := bufio.NewReader(f)
    
        buf := make([]byte, 10) // 按照长度读取
        n, err := r.Read(buf)
    
        fmt.Println(n, err)
    }
    

缓冲区的 r 用于记录读位置，w 用于记录写位置。r 和 w 的区间就是缓冲区有效数据区域，即当前剩余数据。用它可以判断当前缓冲区是否为空，如果 r 和 w
相等代表缓冲区没有剩余数据数据都读完了。

如果缓冲区不为空，把缓冲区剩余数据复制到参数容器中，缓冲区数据剩余多少复制多少，参数容器不一定会填满。

比如参数容器长度 10 字节，如果缓冲区剩余数据 2 字节复制返回 2 字节，剩下 8 字节下次再读，所以返回值 N 是 2 字节。如果缓冲区剩余数据是
20 字节最多复制返回 10 字节。

`copy` 函数复制长度以最小长度为准，如果参数容器小于 `b.buf[b.r:b.w]` 以参数容量为准。复制完设置读位置。

如果缓冲区为空，参数容器与缓冲区如何选择呢

  * 如果参数容器大于等于缓冲区。直接把数据复制到参数容器直接返回。

  * 如果参数容器小于缓冲区。先把数据填充到缓冲区，填充后复制到参数容器。

第一种情况解析：参数长度 100，缓冲区长度 10。

  1. 先复制到缓冲区再从缓冲区复制到参数容器。在系统空间 10 次复制操作到缓冲区，在用户空间缓冲区复制数据 10 次到参数容器，一共复制 20 次。
  2. 直接复制到参数容器。使用参数容器当临时缓冲区，在系统空间复制操作 1 次。缓冲区是数组，参数容器也是数组，把参数容器当临时缓冲区直接从系统空间复制 100 数据。

系统设计中常见的做法是缓冲区空间不能满足参数容器条件，可以使用参数容器当作临时缓冲区。因为缓冲区为空，把数据复制到参数容器对缓冲区的状态没有任何影响。

第二种情况解析：参数长度 10，缓冲区长度 100。

  1. 直接复制到参数容器。在系统空间复制操作 10 次，调用 10 次系统调用。
  2. 先复制到缓冲区再从缓冲区复制到参数容器。在系统空间一次复制操作 100 到缓冲区，在用户空间缓冲区复制数据 10 次到参数容器。

所以先把数据填充到缓冲区，减少系统调用次数，缓冲区填满后再复制到参数。

fill 填充

如果缓冲区有剩余的数据，剩余的数据可能在中间某一段，首先要把剩余的数据往前挪，后面都是剩余空间。流数据是有序的，流上的每一个字节的数据都有序号，所以需要保证它的顺序。

首先 r 大于 0
代表读位置在缓冲区中间。填充前首先确保左边是剩余数据，后边是空白空间。这样才能保证下次的读操作顺序。首先把剩余数据搬到左边，调用系统调用读数据，读数据可能导致失败会重试多次。从写位置填充数据直到结束，更新读位置。

缓冲区可以用数组实现环状先进先出队列，填充数据后可以继续填充，避免数据从中间搬到前面一次数据复制。缓冲区非常小的情况下，复制操作在汇编层面会优化，所以复制操作不是性能瓶颈。缓冲区非常大的情况下，缓冲区读数据和填充数据是串行操作，否则位置发生变化，读数据时空间不够先填充数据，填充满了再把数据返回用户。不过有的业务场景读操作和填充操作是并行操作，则应该考虑用环状队列实现。

##### Discard 操作

`Discard` 就是先读再填充直到满足跳过多少字节。比如一段数据流，读取头部信息时发现 CRC
校验失败，数据包错误，后面数据不再需要，但是数据需要读出来不然一直在管道里，读出来没有必要复制到参数中直接丢弃。

实现原理是首先判断跳过多少字节，因为跳过的数据可能在缓冲区也可能不在缓冲区，所以判断当前缓冲区剩多少数据，如果数据不满足还需要填充数据甚至填充多次直到满足为止，因为这些数据必须从管道里读出来。

流操作实际上是管道中一条流水线，当管道里的数据有错误数据，需要把它从管道中读出来，把剩下来错误的数据直接读到缓冲区。用缓冲区作为临时存储点直接放弃，实际调整读和写的位置实现丢弃，没有必要从缓冲区复制到用户参数中。

##### Peek 操作

`Peek` 定位操作，直接调整缓冲区的读写位置把不要的数据跳过，和上面非常类似。

比如有一个文件 1000 字节，这个文件最终会放到缓冲区，如果缓冲区长度是 10，需求从第 90 位置读数据。有两种方法，第一种方法利用操作系统 seek
定位直接从 90 位置读数据，则刷到缓冲区的数据是已经定位的。第二种方法把前面数据填充到缓冲区直接抛弃前 90 数据。

os 包的 `Seek` 函数可以定位到某个区域读取，文件数据是固定的很容易定位，为什么缓冲 IO 不使用系统定位的操作呢？

缓冲 IO 接受的参数可能不是文件，可能是网络操作。这时跳过前 90 字节，只能先用缓冲区把前 90 字节全部接收不返回用户，接收 90
字节后再接收的数据才返回给用户。因为跳过操作是接收端的行为和发送端没有关系。

缓冲 IO 设计时不能依赖某种特定场景而依赖通用的 IO 操作，因为缓冲 IO 接收的可能是文件 IO、网络 IO 甚至其他 IO。如果接收参数是
`ReadSeeker`
接口要求支持定位的。但作为通用接口设计不能要求必须支持。因为网络操作发送方和接收方之间没有关系。基于接口最小化原则，没有定位操作只能把跳过的数据全部填充，填充完全部抛弃。

##### Reset 操作

`Reset` 操作是无论缓冲区有没有数据，直接构建新的 Reader，原来的 Reader 让垃圾回收器释放。

##### ReadSlice 操作

其他 Read 操作复杂度不高，无非是在简单操作基础之上加点处理。

#### Writer

读操作和写操作的缓冲区是分开的，因为读操作和写操作的状态是分离的，但是它们底层是共用操作系统的缓冲区。

首先判断是否已经是 bufio.Writer，是的话直接用。

##### Write 操作

Write 操作首先要判断参数容器长度是否大于缓冲区。

如果缓冲区不为空，写入参数容器一些数据把缓冲区填满，填满缓冲区后执行刷操作，刷完缓冲区为空。

如果缓冲区为空：

  * 如果参数容器大于等于缓冲区。直接把参数容器数据刷到操作系统缓冲区。

  * 如果参数容器小于缓冲区。直接把参数容器写到缓冲区，填满缓冲区后执行刷操作。

实际上这是一个优化策略，尽可能跳过缓冲区减少中间数据复制的行为。但是可以优化无论缓冲区有多少剩余数据，没必要把缓冲区填满直接刷到操作系统缓冲区，可以节省一次复制操作。

`flush` 刷数据有两种情况，第一种情况是直接刷到操作系统缓冲区，第二种刷到上一级，因为嵌套层级可能非常多。

##### Reset 操作

重置操作，Reader 有状态，Writer 只需要重置相关值。

##### WriteString 操作

写字符串不判断缓冲区直接复制，很显然是 Write 操作的简化版本，Write
操作有判断缓冲区为空，拿自己当做临时缓冲区。写字符串不需要填充缓冲区然后刷缓冲区。写字符串会涉及转换的问题。

#### 小结

缓冲 IO 操作没有复杂的技术实现，主要需要考虑几个相关的细节。就是传入底层 IO 或者文件 IO 或者网络 IO
和一个缓冲区。通过两个位置计数器来确定当前读写位置。某些时候我们应该绕过缓冲区直接使用参数容器当做临时缓冲区使用，来减少复制次数和系统调用次数。

### bytes.buffer

#### 缓冲区

缓冲区就是临时储存点，缓冲区有时候称之为 Cache，Cache 的生命周期更长一些，缓冲区大多数只是临时使用。

比如创建一个字节数组就是一个 Buffer，可以添加一些数据，根本不需要考虑扩容和收缩，因为它的生命周期很短。但是它和设计的数据结构是两码事。

我们设计一个简单的缓冲区就是在内存中或者在硬盘中开辟简单存储，可能是一个数组或者一个切片，数组提供存储，包装一些 IO 相关的方法，称之为 cache
或者缓冲区。

我们设计一个完整的缓冲区除了对外提供读写操作，还需要扩容和压缩。一开始是相对较小的初始化空间，可能是 64 字节或者
4k。缓冲区在某个热点时期大量读和写，如果写的速度高于读的速度缓冲区需要扩容。

如果读操作阻塞导致写数据大量增加，空间被扩大的很大，后来读的速度跟上来写的速度降下来以后，有大量的空间处于闲置状态，利用率很低，读和写怎么保证空间利用率是最平衡的状态。

显然设计一个缓冲区并不简单。缓冲区的算法有两个关键，第一保证内存利用率很高，第二保证性能足够快。缓冲区的目标是合并多个操作变成批处理来减少 IO
操作次数。缓冲区有点像内存分配器，怎么做到在内存和性能之间找到很好的平衡点。

#### Buffer 字节缓冲区实现

Go 提供一个很标准的 Buffer，基于字节的缓冲区，它实现了 IO 常用所有接口，读写收缩。换句话说 socket、文件、内存基于这个 Buffer
进行 IO 操作只要实现 IO 相关接口，这三种可以认为是一种数据流向。我们对于它实现的接口不感兴趣，感兴趣的的是它怎么样维持利用率和性能问题。这个
Buffer 设计可以用来当作学习的案例。

Buffer 内部结构非常简单：

有个基于字节切片的数据容器 `buf`。自带初始化缓冲区是一个很常见的设计。大多数情况下简单使用用不到 64
字节，创建结构体时，内部数组缓冲区不需要额外创建，数组的内存直接嵌入到 Buffer 的。优点是不需要再执行内存分配操作，创建 Buffer
变量时，已经自带 64 字节数据内存在栈上初始化了，没有必要在堆上分配第二次内存。

如果使用的内存超出限制会额外分配。这是很常见的做法，对于操作很频繁的数据尽可能减少内存分配，平时编写程序可以鉴戒这种策略，就是自带一个很小的初始化内存区域块用来应付非常频繁小对象操作。很多内置数据结构都会使用类似的设计。

有个偏移量位置 `off`
用来记录读的位置。它只记录读的位置没有记录写的位置，因为切片有长度和容量，写的位置就是长度，写永远是往后追加操作。数据流都是往后追加。

提供两种方法创建 Buffer，第一种是提供初始化的数据，第二种提供字符串。

### 源码解读

#### Grow, Truncate 操作

扩容时候首先要确定字节切片处于什么状态，缓冲区最常见的状态是数据没有写满，可能在中间某个区域，左边历史数据不再使用，右边有空余部分。为了方便描述数据把左边称之为左空位，右边称之为右空位。

`b.Len()` 用来返回可用数据有多长，说白了就是把长度 `len(b.buf)` 减去 `off` 用来计算当前缓冲区还有多少数据。

这时候判断如果缓冲区 `m` 数据为 0，但是读的位置 `off` 不等于 0，如果 `off` 位置和长度位置 `len(b.buf)`
是相等的，也就意味着读的位置和写的位置重合了，但是 `off` 位置不等于 0，也就意味着这个缓冲区有必要做归零处理，归零就是把它的状态重置，把 `off`
设置为 0。

`Truncate` 操作就是设置状态归零处理。

所以在扩容之前首先判断这件事。

接下来判断 buffer 区域，也就是数据区域的总长度 `len(b.buf)`，`n` 是扩容以保证写入 n 个数据进去，说白了要计算右空位足够写进 n
个数据进去。`len(b.buf)+n` 代表扩容后新的容量，看它有没有突破原始容量 `cap(b.buf)`，说白了计算右空位空间是否够用，是否能保证写进
n 个数据。

如果这个值大于右空位就需要扩容，如果小于或等于右空位就没有必要扩容。

没必要扩容就把相应的切片空间赋值，然后调整相关位置。

我们现在更关心的是扩容怎么处理，扩容时候会处理三个策略。

第一种在创建 buffer 空间的时候，数据结构是 `buf`，如果初始化的时候不给初始化容器直接 nil，那么 `buf` 等于空。

    
    
    buf := bytes.NewBuffer(nil)
    

如果第一次使用 `buf` 是空的，同时扩张的空间小于 64 字节，为什么是 64 字节，L1 是缓存是通过 Cache Line 缓存，大多数 CPU 的
cache line 长度是 64，它必须保证这个数据在一个 cache line 上，不会导致假共享。因为自带 64 字节空间，那么直接把 `buf`
指向 `bootstrap` 数组，这样就直接使用自带 64 字节数组作为 buf 存储空间。第一次使用或者没有超过长度限制的时候会尝试使用内部自带的
bootstrap 内存。

第二种可能是 m 是当前已经有的数据区，n 是接下来要写的数据区，m+n 是接下来要存储的实际数据的长度，m+n
小于整个空间的一半也就意味着左空位和右空位超出一半的空间，这样的情况下它的空间利用率比较低。因为现在已有的数据加上接下来要写的数据还没有使用到当前数据容器的一半，那么这个时候肯定没有必要进行扩容处理。

**因为空间利用率非常的低，还没有用过超过一半。**

把当前已经有的数据搬到 0 的位置，右边就空出来了。接下来就变成数据都在左边的状态了，右边的空间肯定大于
n。这时候就是考虑到当空间利用率非常低的时候，就尝试做压缩处理。其实 java 中压缩 GC
都这么做的，垃圾回收以后会把活着的对象全部压缩到左边紧凑的区域，右边可以空出来连续的地址分配，因为不管什么时候连续的地址分配都可以减少碎片化。

第三种可能是这两块空间加起来大于它的一半。举个例子，数据空间的容量 cap 等于 10。当前已有的数据长度 m 是 4，要写的数据 n 等于 2，那么
m+n 等于 6 肯定大于 cap 的 1/2。剩余空间足以写下这些数据，但是需要判断右空位多少个。

通常情况下对于内存管理来说会抛弃这种策略，它会发现这时候空间利用率大于 50% 的时候，考虑的策略不是做压缩处理，只有在空间利用率小于 50%
的时候做压缩处理，当大于 50% 的时候并不是考虑使用剩余的空间，因为要遵循一个原则，当空间利用率大于 50%
的时候可能意味着当前写的效率可能大于读的效率，基于这种准则情况下，它要做的不是说去压缩也是去判断右空位够不够，而是做的是要提前为接下来的写操作分配空间。

多数时候正常人的写法是先判断右空位够不够用，可能够用也可能不够用，这样的做法是正好为当前这次写做出了处理。这种策略是没错的，指的是正好为当前这次写做出了处理，如果判断右边空间是否够用情况下，实际上做的前提是为当前一次写做出合理的策略，但是没有为接下来的写操作提前做好准备。对于一种高效的内存管理软件来说，它的策略和正常想法是不一样的，因为我们多数应用人员只考虑单次操作，而对于系统程序员来说考虑的是提前分配。

空间利用率大于 50% 的情况下，不需要为当前一次操作进行优化，而为之后 N
次操作提出优化，这是两种不同的思路。判断的依据标准是空间利用率，对于系统程序员判断的是空间利用率百分比，应用程序员判断的是右边空间是否够用。因为我们接下来连续快速写操作的情况下，我们尽可能减少写操作被阻塞，因为接下来写操作处理的话，空间利用率大于
50% 也就意味着假设接下来有快速的写操作，应该提前做好准备。这是一种策略。策略很多时候是提前做准备的。

那么这时候进行两倍扩容，把当前空间总容量乘以 2 再加上 N 确保写入 N
个数据。扩容完了以后把数据复制到新的空间里面去，这其实有些像内存分配空间连续栈的策略。

这地方关键在于程序员的思路，系统程序员的思路和应用程序员思路在很多时候差别非常的大。假设当前空间是 10，现在已经有的数据假设是
m=4，那么我们想往里面写入 n=2 个数据，m+n=6>5，5 是 1/2 容量，接下来的问题在于判断右空位的空间是否大于等于 2，才能写入 m
数据。有几种可能。右空位空间可能是 0，左边是 6。

右空间有很多种可能，这时候需要判断右空间能不能写，可能是 0 或者 1 不能写，通常的做法是进行一次压缩处理，把数据全部搬到左边，右边可以保证有 6
个空位足以写下 2
个，然后接下来去写。问题在于我们这种策略只是为当前这一次写做出了优化。对于应用程序员来说我们关注的是单次逻辑，应用程序员很少会考虑全局的或者连续的策略。通常情况我们大部分应用程序员考虑的是单次的策略，或者单次操作，单个逻辑、单次请求。

但是对于数据流，我们需要考虑的是读和写是连续性的、不是单次操作。那么作为一个系统级容器，单次优化的话他的整体效率会很低。所以系统程序员在这地方考虑的是当空间利用率大于
50% 的时候，也就意味着读和写的平衡可能会被打破，可能接下来面临写快过读，如果写快过读的话也就意味着右空间会频繁的面临空间不够的状况。

如果写的速度大于读，那么右空间就会连续性的面临空间不够。那么还用之前的策略的话很显然整体的操作效率会很低。它会考虑的是这时候不是做压缩处理而是扩容，扩容 2
倍的 x 加上 n，加上 n 因为不知道扩容 2x 之后是否还能满足 n 的需求。假设 n=10，乘以 2 等于 20，N 可能等于
40，扩容两倍还是不满足。所以它的扩容空间是两倍空间加上 N 确保这次扩容后肯定能满足这次需求。

接下来扩容完了会把历史数据复制到前面，后面有大段的连续空间为接下来高频度写操作提供连续性的空间来避免频繁扩容，避免频繁压缩。因为当空间利用率超过 50%
的时候会把天平朝性能这一方进行调整，它的策略非常简单，认为接下来要面临大量的写操作。

但是我们可以注意到这种策略相对来说过于粗暴了一点，相对来说太简单，扩容之后接下来空间变得非常大，用不了这么多空间利用率下降的很严重。所以内存分配器连续栈的扩容策略比这复杂的多，不是简单的
2 倍扩容，它会判断当前容量多大，比如小于 10M 都进行 2 倍扩容，大于 100M 按照 1/4 扩容，大于 1G
的话按照百分之一扩容，因为当基础容量非常大的时候每次按照 2 倍扩容效率非常低，最好的方式根据当前容量进行调整。

所以这个 Buffer
设计针对简单场合，数据量不大的场合使用。这不太适合作为专业级缓存容器使用。专业缓存容器空间有时变得非常大，有时变得非常小。比如冷启动因为大量的命中或者是某个热点的时候，导致热数据增多，后来数据被冷却。TTL
会删除这样的大量不再被访问数据，这个时候空间利用率就很低。

所以通过研究代码我们知道它适合用来做什么？它内部是怎么操作，它的策略是什么样。所以它适合用来学习，因为非常简单，先学习这个再去研究一些更复杂容器的时候，起码知道有个基础策略，简单版本怎么做的，复杂版本在这基础之上又做了什么。

基本版本有三个策略，初始化时尽可能使用自带的。如果空间利用率低于一半进行压缩处理。空间利用率高于一半进行两倍扩容处理，为接下来的写操作提供足够的空间，这是一种常见的策略。

需要考虑是为单次操作优化还是为连续操作优化，这是两种不同的思维。应用程序员更多关注怎么满足当前的单次请求，很少会考虑接下来是否会有连续性的这种操作。比如操作系统进行缓存有乐观命中策略，访问一个数据按照
64
字节缓存，它会把后面连续的数据全部缓存。因为操作系统认为访问后面的数据可能性会非常高。很多数据库访问表的时候，连续遍历提前把后面的数据从冷数据变成热数据，接下来查询会变得很快。

这些策略和写逻辑代码有很大的不同，需要转换自己的思维。以后设计系统级容器或者设计系统级算法的时候，是否为连续操作或者后面可能的状况提前做优化，是衡量一个程序员的一个基础素质。如果每次为当前多次操作做精确操作只能表明满足了需求，但是并没有满足长时间运转的场景。因为长时间运转的话，我们尽可能要提前准备。缓存提前把数据从冷数据变成热数据就是很典型的场景。

我们把单次的行为称之为操作，多次提前准备的多次连续行为称之策略。策略会走在操作之前。

我们现在知道就是写简单级别的缓存器，也需要考虑超出我们写代码的那些思维。

##### Truncate 操作

Truncate 截断只需要保证保留多少个有效数据。在文件操作里会截断一个文件。假设管道中 m=6，进行截断操作只保留 2
个，只需要把长度从原来地方指向新的位置，就相当于 off+2 作为长度，这就是切片的重新切片。保留多少个数据就是把写的位置和读的位置加上新的做重新切片。

如果保留是 0，只要把读的位置变为零，N 变成是 0，实际上切片就被重置了。

##### Reset 操作

Reset 就是置零，把所有相关状态全部归零。

##### Write 操作

写操作首先通过扩容来确保可以写入这么多数据，扩容只是一种行为，并不表示真的扩展内存了，扩容主要为了确保右空位可以写入 n
个数据。接下来把数据复制进去就可以了。

##### Read 操作

读操作先要判断读写位置，`b.off` 是读位置，`len(b.buf)`
是当前有效数据结尾位置。如果这两个位置重叠实际上就是里面没有多余数据，就做归零处理。如果没有的话复制数据，同时累加读位置计数器。

### pipe

pipe 通常称之为管道，管道本身是历史很悠久的产物，在 Linux 编程下管道非常常见，可能是进程内通讯，也可能是跨进程通讯，类似于 ipc
通讯都会用到。

当你创建管道的时候，这个管道内可以流通数据，它会同时返回两个文件句柄，一个文件句柄是用来写的，一个文件句柄是用来读的，一个只写一个只读。

最常见的做法在父进程中创建读和写生成两个子进程，子进程可以继承父进程的文件表，一个进程专门用来写一个进程专门用来读，这样可以在两个进程之间进行 ipc
通信，这是很常见的做法。

至于管道用什么技术实现，如果单个进程当中基于内存共享实现，就是一个进程内基于文件共享实现。如果跨进程的话可以直接在底层通过 socket 实现，socket
不一定通过网卡，有一种是通过 unix 方式，在单台机器内部通讯不会有复杂的网卡链路。一般的情况下，网络操作 `net` 包有 tcp、udp、unix
三种，unix 其实用 socket 实现但是不走网卡链路直接在内核当中进行数据交换，看上去整个操作方式像 socket
实际上并不走网卡，常用来在单台机器内实现通信逻辑，它效率很高。

pipe 操作方式有点像 channel，channel 也是管道，管道内部传递数据，只不过区别在于 channel
默认情况下是双向的，每端可以写可以读，但是我们可以把它变成单向操作。

pipe 和 channel 有什么区别，channel 更像消息队列
MQ，发送的是一个一个消息包，只不过每个消息包是一个对象，但是一个对象实际上就是一个包，包含了一个完整的数据边界，发消息队列里面数据，其实发一个一个消息包，包可能是一个对象完整序列化，可能是一段数据，是以包的方式发送的，然后对每个包实现
ack 验证，甚至把包转发给不同接收端。

而 pipe
基于流的方式，发送一连串的数据，数据只有开始和结束，什么时候开始知道，什么时候结束很难有明确的边界，写操作可能是外在条件确定什么时候结束，它发送的是数据流而不是包，如果是包谁先到谁后到没有关系，谁先消费谁后消费都没有关系，只要保证单个包的逻辑不会被拆分。

消息队列的策略是包被第一个消费者拿走，第一个消费者拿到包之后由于某种原因意外奔溃没有返回 ack
信息，包还会保留在队列里面可能还会被第二个消费者重新拿到，消息队列的策略是最少被读取一次或者最少被确认一次，包谁先到谁后到谁先被消费谁后被消费不关心。

数据流发送的数据每个字节都是有顺序的，内部按 A 和 B 方向传递数据，B 肯定先达到、B 肯定先读到。channel 以包为单位发送数据，pipe
发送的数据流。channel 像送快递的，pipe 像是流水线，必须按照顺序组装。

#### 设计思路

如果自己去设计 pipe，涉及一个读一个写，写的话把数据写到缓冲器，读的话从里面读，中间提供类似 buffer 空间，在单个进程内情况下 buffer 和
pipe 有点类似。buffer 必须有个数据容器，buffer 关注焦点是存储，pipe 关注的是数据交换。它们关注焦点不一样，pipe
并不关心数据怎么存，而关心的是一方写完数据交给另外一方读，它关心的是交换的过程，buffer 关注焦点在存储上，所以有扩容压缩，而 pipe
关心的是谁读谁写，在没有读之前写面临阻塞，更关心的是数据交换行为，所以它们都可以用来在两端传递数据，pipe 读写目标是非常明确的，FD 是确认的，但是
buffer 读写是不确定的，可能有多个。

#### 源码解读

pipe 本身是并发安全的容器，它更关心的是行为而不是数据存储。它有多个锁，两个条件用来单播和广播进行唤醒通知。它有一个数据容器，数据容器没有读写位置标记。

我们怎么去判断有哪些数据读哪些数据写？写到哪读到哪？它的读写操作怎么协同的？

##### write

先看写操作，首先如果写的数据为
nil，它做了简单的处理保证写入的数据是零数据，写数据是零数据也是写，写操作读操作关注的是行为的时候写零数据也会触发一次行为，这与 buffer
不一样，buffer 写零数据关心的是存储直接忽略掉。关注存储时候数据为零忽略掉，关注行为时候数据为零触发写操作。

写操作触发锁操作，有锁竞争效应通知效应，接下来为写操作进行加锁，先确保写操作当前是唯一的。

接下来请求条件锁，条件锁是用来在读和写之间进行相互通知，它有两个错误值判断读和写是否已经关闭，如果已经关闭的话不能再接着写，有两个状态是用来保存读和写当前是否已经关闭，如果已经关闭情况下就不能再进行处理。

接下来直接持有待写入数据。写入数据的时候 data 指向的是参数 b，所以 data
根本不是一个容器，它只是用来临时保存要写入的数据，因为写操作没有结束之前有锁的存在确保这个数据是独享的，它只是把准备写入数据临时持有，它内部根本没有数据容器。

所以它关注的行为，而不是数据容器，它关心的是读和写操作。既然只是把数据传递给某读操作，pipe 不准备容器，pipe
只是流水线没有数据，数据传入方有就行了，pipe 不需要复制过来，直接拿到数据的引用就可以了。

接下来会唤醒某个读操作，读操作可能有多个读。现在有数据了通知读操作来读，这看上去有点像同步通道唤醒某个读操作，同步通道更关心的是行为，异步通道关心的是容器。

接下来进入循环等待，因为唤醒只是发出信号，对方什么时候去操作写数据这边不知道，写操作拿到数据，自己不生产数据和复制数据，只是拿到数据，所以进行循环等待。

首先需要判断什么时候结束，只要读操作拿走数据就行了，并不关心谁来读。如果数据拿走的情况下，data 就为
nil，不用等了跳出循环，它的判断标准是数据是否被读取。如果数据没有被拿走情况下需要判断读操作是否关闭，关闭的意思是永远不会有人来。接下来判断写操作是否关闭，如果这些都处理不了，也就意味着还有人，只不过现在还没来，那就等。

这地方还有另外一种可能在于数据不见得一次被拿走。可能有 20 数据，对方每次只能拿 2，来来回跑 10 次或者 10
个读对方才能把数据全部取完，不一定一次，这和管道很大不同。通道是把数据包丢过去，对方肯定会把整个拿走。但是对于数据流不一样，对方未必一次能拿走。实际上需要等整个数据为空，所有的数据全部被拿走，所以利用循环来做这件事，它的判断依据很有意思，第一数据全部为空。第二确保有读操作，还有写操作没有提前终止。

如果循环结束的情况下表示数据全部拿走，要么是跳出终止循环，要么是错误终止循环，如果数据全部拿走后表示写操作可以结束，相应的这些锁就会被释放掉。

写操作实际上是一种同步方式，行为非常像同步通道。它先获取锁，然后持有数据，因为内部没有容器，数据是由参数提供的，然后发送信号唤醒某个读操作，然后进入一种等待循环状态，最核心的问题是怎么样进行数据检查，怎么样结束这个等待循环，那么数据全部读完跳出，还有种可能是数据一次拿不完，需要多次读操作，所以用循环实现同步操作。

也就是写操作必须等读操作把数据全部取走了才能结束，这样一来的好处是传入的参数交给了写操作，写操作只是把数据交给了某个读操作，然后写操作结束。所以写操作只管理数据传送行为，根本不关心数据怎么存储，因为传入参数会受到条件锁的保护，确保参数在当前状态下只有一个人处理。还会保证不会有两个写操作同时传递两个数据进来，因为有锁的存在，写操作
1 没有完成任务之前写操作 2
处于阻塞状态，这就是保证流的顺序问题。如果多个写操作交叉操作那么流的顺序肯定出错了，因为不能保证传入数据的流是连续的，因为读操作可能是分段读不是一次性读完的。

写操作和读操作之间是存在同步的，写操作必须保证把当前数据全部拿走才能进行下一次写操作。这也是和 buffer 有很大不同的地方。

##### read

读操作首先确保读的时候只有一个人读。就是每次从管道里面读数据只有一个人，那么也有个读锁，确保读操作只有一个人完成。

接下来有相应条件锁，是为了待会发送信号时候确保信号可以发给读和写两边。

那么接下来也是进入循环状态，因为写数据也有可能比读数据后到，类似同步通道，发送数据先到，也有可能接收数据先到，首先判断读操作是否关闭，如果关闭就不读了，接下来判断是否有数据，已经没有数据没必要读，还有需要判断写操作是否结束，最后进入等待状态，就意味着没有数据，没人来的情况下才会没有数据，就是写操作写入数据为
nil 也是零数据确保 data 不等于 nil 对象，所以通过 data!=nil
来判断肯定有写数据，然后进入睡眠状态，如果现在有送数据的人来了，发送给读操作信号，发送信号之前肯定有数据，写操作是先有数据再发送信号的，所以读操作醒的时候可能能拿到数据，无非是有数据和没数据。

我们注意到它们关注的都是行为，通过循环来确保等待有写操作到达，如果来了，这时候就开始复制数据，复制数据时候，它的参数决定一次可以拷多少，拿完以后会判断数据是否全部拿完，如果全部拿完的情况下，发送信号唤醒写操作，写操作通过判断
data==nil 是否拿完数据。所以读操作是有责任来唤醒写操作。同时关注一点是，当有多个读操作时候，只有最后一个才会去唤醒。

写操作和读操作，写操作一次传入 20M 数据，进入休眠状态，读操作每次读 2M，只有最后一个读操作数据才会为零，数据设置为
nil，然后唤醒写操作，写操作重新进入循环，检查数据是否为 nil 知道数据被消费完了，然后写操作才会结束。

pipe
显然是一种同步数据结构，简单来说是写操作写到一个区域，转到多个读操作，读操作结束以后，写操作恢复。很显然写操作和读操作构成一种同步操作。所以写操作根本没有必要提供数据容器。因为读操作每次拿到传入数据的一部分，最后把传入数据消费空了。然后把参数还给对方，没有必要存储数据。所以
pipe 更关心的是读操作写操作的行为，关心的不是数据存储，而关心的是数据传递的行为，这是和 buffer 很大的差异，buffer 关心数据怎么存储。

它们适用不同的场景，有些时候我们有一连串的写操作，把数据进行缓存，然后把数据一次性读出来，这种批操作适合
buffer。有些时候我们更关心把数据传递另外一方，另外一方在某点确定数据被对方全部拿走，关心的是把数据传给另外一方，读和写操作关心的是写的数据在某一点确保被读的一方拿到，然后继续接下来写操作。所以
pipe
更多时候不是做缓存而是适合做通讯。这种通讯是基于数据流的通讯，而不是基于固定包大小通讯，这种通讯更适合用来传递数据，而通道适合做消息，它的焦点是数据本身，数据和消息虽然有些类似，但是还是不一样的，消息表示一种特定的状态，比如某个
User 对象，而数据可能是无状态的，数据很多时候就是传递 100
字节，至于内部什么结构可能不清楚，而消息不管进行序列化还是反序列化，它是有特定的格式和状态。所以我们并不适合用通道传递数据，每个对象序列化
10M，消息通常来说大小可能是固定的，数据肯定是流式的。数据可能是接收 EOF 代表结束，消息可能是长度。

我们通常在网络栈上面有 Ip 包，在 Ip 包之上有 tcp、udp。tcp 之上有 http。Ip 更像流通信，tcp、udp
更像消息通信，消息通讯更关心的是消息格式，尤其是 http，http 协议规定了头有多大。下载文件传递文件走 ftp 走流的通讯，这种流通讯更像 tcp
协议，只有接收 EOF 才会结束。

我们对于连续性数据传递的时候选择什么样的东西，某些时候用 pipe 替代 Buffer，对于大数据交换，我们用 buffer 并不合理，因为 buffer
这种设计并不适合存储太大的数据，那么用 pipe
的好处在于每次写数据可以确保读操作能快速消费完，消费完以后的话接下来写下一部分，这样的话可以避免大量的内存占用，因为使用 pipe
更关心的是写和读之间的平衡，内存中不需要持有这些数据，一旦读完的数据立马失效，因为读操作和写操作之间是同步关系，更关心读和写的平衡，确保写入的数据立即会被读走，读走完了以后接着写，这样内存消耗会很小，所以适合大数据交换，因为大数据交换一旦读操作某种原因挂了那么接下来往里面写是没有意义的。因为数据交换是行为，buffer
缓存关心的是提供容器，把零碎的数据收集起来，最后进行一次批操作，它更关心的是数据本身，把零散的数据变成大的数据。它们的使用场景虽然有些类似，但是还是不太一样的。

另外 pipe 不见得都是基于内存实现的，这只是一种模式，设计方式也不太一样，Go 有不同的 pipe，比如 io
实现的是基于内存交换的，还有基于文件来交换的，还有基于网络来交换的，这只是一种通用的设计，但是这种思想决定了究竟设计这样这种结构，读和写相互之间操作是怎么样处理的，它们相互之间怎么样去协作的。

读操作和写操作如果有一边关闭会立即发送一个信号确保向两端发送信号从睡眠状态退出。

