---
html:
  embed_local_images: false
  embed_svg: true
  offline: false
  toc: true
print_background: false
export_on_save:
  html: true
  puppeteer: true
---
严格来说 goroutine 不能从字面层来翻译称之为协程，它实际上是一套相对完整的虚拟机。

### goroutine 模型

Go 语言的 goroutine 模型相对来说设计的不错，goroutine 模型使用的是多对多模型。多对多模型被一些操作系统一些语言 Rust、Java
抛弃，而改用一对一模型，因为一对一模型性能高，但是对于海量的并发操作未必是最优秀的。

Go 语言更适合 IO 密集型，对 CPU 密集型来说它对运行时调度不是很合理，它对 CPU 密集计算上不是很好，但是在 IO 密集上做的很好。

### PMG 模型

调度器最根本的任务就是让多个 goroutine 执行。第一确保 goroutine 能执行，第二确保 goroutine 尽可能快执行，第三确保多个
goroutine 之间公平性。

我们抛开硬件只说基本架构，goroutine
本身是基于并发设计的。如果它是虚拟机的话，它首先需要处理器，处理器决定了同时可以运行任务的数量。其次需要并发任务。最后需要具体执行机构，进程的执行机构是线程，在这里把线程抽象出线程。因为运行时是单进程，所以不需要额外的任务调度，三种机构基本可以完成。

![](https://images.gitbook.cn/tY4u0U)

我们用一个示意图，PMG 模型代表处理器来控制并发，线程负责具体执行，并发任务来保存任务状态，各自承担自己的角色，共同协作来完成并发任务执行。

下面详细描述各种对象的指责

### P 对象

运行时怎么抽象这个并发模型呢，首先抽象出一个概念叫 P，代表处理器的意思。P 控制并发的数量，即控制同时可以执行的线程的数量。把 P 的数量限制为 4
意味着只能同时执行四个线程，至于怎么映射到线程上，怎么去调用，怎么去执行是操作系统关心的。

处理器是运行时抽象的概念，类似 CPU 核，它不是物理 CPU
不能执行，线程是实际执行，当它的队列中有任务时，它会创建或者唤醒系统线程执行队列中的任务。所以处理器和线程需要绑定形成一个具体的执行单位。相反，线程不绑定处理器也不具备执行权限。处理器数量决定并发任务数量。默认情况下处理器的数量是固定的，它和逻辑
CPU 核的数量相同，也可以设置。

严格意义上来说，P 只是一种控制单位，控制并发。P 不是真实的处理器，既然是控制单位，也就意味着有点像令牌，拿到令牌才能执行，用令牌的数量控制多少个 M
可以执行。

所以处理器真正意义上做两件事，第一线程必须和处理器绑定，相对于获取执行令牌。第二绑定后获取并发任务资源。

### M 对象

执行单位 M 是线程，所有的代码须由线程执行。所有线程必须调度到处理器上才能执行，这与操作系统的线程的概念是一致的。比如有 100 个 M、4 个 P，这
100 个 M 只有 4 个 M 能绑定 P 执行。

M 是用来执行的，每个 M 对应一个线程，所以 P 的数量和 M 数量不相等。类似 cpu
的数量和线程数量不相等。任何一个进程可以创建更多的线程，多个应用程序加起来线程的数量远远超出 cpu 的数量。任何一个任务最终都要交到 M
上去执行，要么放到主线程上执行，要么单独创建线程执行。

线程有两种状态，休眠队列和正常队列。

休眠队列保存的是没有并发任务执行的线程或者没有和处理器绑定的线程，因为线程只有和处理器相绑定才能执行。

### G 对象

另一个角色是 G 对象就是 goroutine，程序启动有默认的 goroutine，类似主线程。每个 `go func` 语句会创建一个 G
对象。严格意义上来说 G
对象是数据包，它打包需要的数据，第一执行函数的指针；第二所需要的参数，参数涉及到立即求值，因为参数复制需要保存，如果是指针还涉及逃逸行为；第三分配栈内存，用于执行状态的栈，保存上下文空间，这些打包成
G 对象。

执行任务的状态保存在栈和堆上，G 对象有自己的栈，默认可能有 2k、8k，堆是全局的。另外上下文切换的状态，需要保存寄存器值。

#### 本地队列和全局队列

我们创建大量的并发任务，并发任务创建后保存在本地队列或者全局队列。

本地队列，例如 A 任务创建 B 任务，B 任务保存到当前处理器本地队列，这个队列用来保存本地运行的并发任务对象。

全局队列，全局队列的作用是在多个处理器之间平衡并发任务，类似操作系统中有 4 个核，有 100 个进程需要执行，最优的方式 4 个核平摊执行这些进程。

当线程绑定处理器后，优先从当前绑定的处理器本地队列取任务，如果本地队列没有任务则在全局队列里获取，如果全局队列没有，则从其他的处理器的本地队列获取。利用两级平衡机制，第一个全局队列，第二个其他处理器的本地队列，确保任务尽可能快的执行。从调度器角度来说，尽可能让所有等待执行的任务全部完成才最合理。

当前绑定的处理器本地队列是私有的，获取任务不需要加锁。全局队列是所有处理器共享的，获取任务加锁会造成性能降低。从其他处理器的本地队列获取任务需要通知对方加锁同时竞争这把锁。所以从本地队列获取任务没有数据竞争不需要锁，本地队列是为了
lock-free 方式快速执行，全局队列是为了多个处理器之间并发任务平衡。

用一个例子说明。比如 main goroutine 执行绑定的是 M0 和 P0，M0 在 P0 线程上调度执行，P0 线程是主线程。G 对象在当前 P0
线程上创建的就会放到 P0 的本地队列。本地队列是环状队列长度默认是 256 个，当然不同版本可能不太一样。

#### 公平性

接下来谁来执行？正常情况下如果没有其他 P
取任务则按顺序处理，但是这种处理方式不太公平，什么时候执行任务要看当前任务什么时候结束，有的任务执行时间比较长，队列里的任务怎么办呢？分几种情况。

第一种情况只要本地队列满了则会转移一半的任务到全局队列，如果其他 P 的本地队列没有任务则从全局队列获取。这样造成任务执行顺序不确定。

第二种情况本地队列执行 60 个需要到全局队列执行一个。

所以创建任务是顺序的，执行任务不是顺序的，影响因素太多，第一本地队列快速执行，其他 P
还没来得及从这个本地队列获取任务，可能是顺序执行的。第二由于操作系统时间片机制，任何一个 P 都有可能抢到任务执行。

所以所谓的公平性就是，第一本地队列超过 256 个任务转移一半任务到全局队列，第二本地队列执行 60 个任务则到全局队列执行一个确保公平性。

#### 执行次序和 `runnext`

正常情况下 G 对象按次序放到本地队列，但是 G 对象还有 `runnext` 属性，用来保存最后一个创建的 G 对象，执行时优先获取 `runnext`。

以例子来说。首先 func1 创建 G1 放到 `runnext` 上，接下来 func2 创建 G2，`runnext` 已经存在，所以 G1 放入
runq 队列，`runnext` 等于 G2。接下来 func3 创建 G3，runq 队列是 G1，G2，`runnext` 等于 G3。

执行 `runnext` 优先，然后 runq 队列，可能先执行 G3。这种算法有点不公平？G1 和 G2 比 G3 先创建，怎么 G3
先执行？这是设计算法上一个假定，因为调度器不知道 G1、G2、G3 执行需要多长时间，假设执行时间很短，如果 G1、G2、G3 所有的 G 对象都是由当前
main goroutine 执行，G3 先执行 G1、G2 再执行，无非就是 G3 插队 G1、G2，不管有多少个 goroutine
只有一个插队，公平相对性可以保证，就算不公平也只是很小范围的不公平。

当有其他 P 出现的时候，`runnext` 的公平性就可以得到保证。优先从队列里去获取，优先获取 G1 则 G1 有提前执行的机会。如果 runnext
保存的是先创建 G1 对象，P 先拿走的是 G2，对 G1 不公平，这样设计其实解决了公平性，因为 `runnext` 即使插队，也只是一个。

正常情况下有多个 P 运行。从全局考虑这个设计的时候，`runnext`
为什么只放最后一个而且先执行的设计思路会发觉挺有意思的。我们在做应用架构设计的时候可能不会考虑，因为分模块分的太细反而限制了我们通盘考虑的这种能力。

创建 goroutine 的次序和执行次序不是对应的，甚至多次执行同一个程序也未必是一致的，或者不同版本执行次序也未必是一致的，因为 runtime
在不停调整和优化，早期版本没有 `runnext` 这种概念。所以只能假定 goroutine
什么时候执行按什么顺序执行是未定的，我们编写代码不能依赖这个次序，如果控制多个 goroutine 按顺序执行，可以利用通道编排执行次序。因为
runtime 的设计不是对外公开的，没有规范没有文档。

#### 性能点建议

我们用 `GODEBUG=schedtrace=1000` 检测调度器状态，runqueue 是全局队列。[] 数组是所有 P 的本地队列。P 的数量
gomaxprocs 和线程数量 threads 不相等。我们尽可能把 G 任务放在本地队列里，全局队列尽可能少，因为全局队列的公平性会越来越弱。

写程序的时候，不要有太多的累积。因为本地队列很小，创建很多 G 任务就转移到全局队列中，这样会造成某些 goroutine
不是饿死，而是需要很长时间才能执行到，饿死指的是永远没有机会执行。

假设 web 应用由于某种原因导致 qps 非常大，每个请求都会创建一个
goroutine，如果来不及处理全局队列就会拥挤大量的任务。应该考虑的是，第一是否需要拆分多个进程处理，多个进程拆分可以确保每个队列会小很多。第二是否需要拆分多台机器，因为拆分多个进程改善有限，cpu
可能忙不过来。如果 CPU 能忙得过来仅仅因为 IO 等待导致拥塞，拆成多进程可以提高处理能力。如果 CPU 处理不了的时候，可能考虑多台机器。

我们可以创建成千上万的任务，不是创建完任务就行了，还需要调度器保证它能尽快的执行，而且保证相对公平的方式执行。

#### 监控程序 sysmon

某个 G 与 M 和 P 两个资源相绑定才能执行。但是 G 的执行时间非常长，如果不处理 G 会占用 M 和 P
导致其他的任务等待。所以调度器在后台启动一个监控程序。它用一个专门线程执行，这个线程不需要 P，它检查所有 P，如果 P 被锁定在某个 G 上的执行时间大于
10 毫秒，就会发出抢占信号。

每个 G 对象都有函数调用。编译器会在这些函数头部插入一些指令，这些指令第一检查内存是否够用，第二检查是否有抢占标志，如果有抢占标志就把这个 G
对象状态保存起来，重新放回队列，把 M 和 P 两个资源释放执行其他任务。这样可以保证队列里的任务都有机会尽可能快地执行，任何一个任务都不应该长时间占有
CPU，这跟操作系统时间片的做法是一样的，操作系统的线程执行时间片用完了，保存寄存器的一些相关状态，把 cpu 交给其他的线程来执行。

为什么把 P 抽象成处理器，因为第一用来控制并发的数量，有多少个 cpu
就能同时运行多少个线程。第二用来控制时间片，第三管理任务队列。在操作系统中不同的线程专门为每一个 CPU 安排一个任务队列去调度。

#### 栈内存

那么换句话说，P 和 M 怎么执行 G 任务呢？M 是一个线程，每个线程都有线程栈内存，这个内存称之为 G0，大小
2KB，用来执行系统指令，就是运行时相关代码。每个 G 对象自带 2KB 内存，线程 M 执行 G 时，线程 M 会把 SP 和 BP 寄存器指向 G
自带的内存执行用户代码，当我们需要重新执行系统指令的时候再把 SP 指向 G0 就可以切换到 G0 内存上，因为栈的所有操作都基于 SP 或者 BP
做偏移计算的。

这样每个 M 会关联两块栈内存，G0 是 M 自带的，用来执行系统指令，G
自带栈内存用来执行用户指令。为什么分开？因为用户指令执行系统指令的时候，用户调用堆栈和系统调用堆栈就混在一块了，还有系统运行的这些指令会污染用户指令，所以把它们分开是有必要的。

M 的所有的状态都保存在 G 任务栈，优点是在任意时 M 都能上下文切换。

M 使用的栈保存在 G 栈上，切换时只需要把 M 使用的 SP 等寄存器保存到 G 的寄存器上，保存后 M 就可以上下文切换。所以 M
可以把函数执行到一半或者任意一个点中断，中断之前把保存现场，这时 G 任务没有执行完成，把 G 对象重新放回任务队列。下一个 M 拿到以后这个没有执行完成
G 任务时，首先恢复 G 任务栈数据，包括堆栈帧、寄存器 SP 恢复，这实际上就可以从断点恢复执行。

当系统调度时，先把当前 G 的运行状态和 SP、BP 寄存器保存到 G 的栈内存中，然后重新放回队列。接下来 M2 执行只要把自己的 SP 指向 G
的栈内存，然后把状态恢复到自己的 SP 寄存器上，剩下的代码就可以在 M2 上执行了。所以同一个 G 任务可能前一段代码在 M1 执行，后面一段代码在 M2
执行。G 的状态还有局部变量保存栈内存而不是保存在线程上。

![](https://images.gitbook.cn/JyyV2P)

goroutine 设计上非常巧妙的地方是：G 的状态是自我持有；M 本身是无状态，可以多路复用。

G
任务可以在中途实现调度、实现临时保存状态，由另外一个线程去恢复。它借鉴了操作系统保存现场的概念，所有函数调用汇编原理是函数有堆栈帧，栈上保存现场，恢复现场。堆栈帧确定一帧一桢的分隔。汇编本身没有函数，汇编只知道
PC 指向哪、SP 指向哪，至于逻辑上的划分跟它没关系。同样的 goroutine 也是这样，任何一个 G 任务都可能保存现场，由另外一个 M 恢复现场。

每个 M 自带的 G0 内存用来执行系统指令的，系统指令不会涉及跨线程执行，但用户代码可能会出现跨线程执行。G 对象只有自带内存才可能实现和线程无关。线程
M 只用于执行不负责维持状态，状态由 G 自己维持。好处就是 G 对象可以在多个不同的线程之间进行调度。

栈内存初始化 2K，当不够用时就会扩容，最大能扩大
1GB，所以编译器才有能力尽可能分配在栈上。扩大内存以后，第一执行完，垃圾回收器会把内存回收。第二没有执行完，它会检查 SP
寄存器，和有效栈帧大小进行比较，如果使用量只有 1/4，就会收缩处理。

这样设计的优点是每个 M 对应一个系统线程，M 本身不保存任何状态，M 的状态保存在 G 中。M 只需要在执行时把它相关的指针和寄存器指向 G
的栈上就可以执行，当 M 不执行 G 任务中途中断，它只需要把状态保存回 G，M 本身什么都没有。

M 不用关心执行哪个 G 任务，因为 G 任务的状态跟 M 没关系。换句话说，G 任务可以由任意 M 来执行，例如 M1 执行切换下次 M2 执行。

### M 和 P 的数量可能不相同

为什么 M 和 P 的数量可能不相同呢？主要涉及系统调用。

假设 P 是 4 个，M 是 100 个，M 要真正执行执行，从抽象层面上它得绑定一个 P，P 一共 4 个也就意味着只有四个 M
能拿到令牌执行。类似操作系统的线程调度到处理器上才能执行，线程和处理器之间存在一种绑定关系。

![](https://images.gitbook.cn/g5pU88)

上图所示 M 和 P 是一个组合，它们绑定一起执行。

这时 G 任务需要执行系统调用，当前线程 M 从用户态切到系统态被阻塞，M 在系统调用之前会主动释放它所绑定的 P，释放的 P 去唤醒另外线程 M2
和它绑定，执行其他的 G 任务。原来 G 任务继续等待直到系统调用完成，完成后有两种状态，第一种 P 还在等待则继续执行，第二种 P
释放或者调度被抢走。这时 G 任务把当前状态保存现场，放回队列，当前 M 回到休眠队列中，这样 M 的数量发生了变化。

系统调用有两种方式失去 P，第一种方式主动释放，比如系统调用默认情况下时间很长比如休眠 5s；第二种方式被动释放，不知道系统调用需要多长时间，比如系统 IO
操作、网络 IO 操作、本地文件 IO 操作。系统监控程序会定期扫描处于阻塞状态下 MP 的组合，如果发现超过 20
毫秒还没有解除阻塞，它就会主动抢走。从系统公平的角度来说，可能还有成千上万的任务在列队等待。

最好方式 G 任务继续等待执行完成，抢走 P 让这个 P 和新的 M 执行其他的任务，造成 M 执行完成有两种状态，第一种是 P 在被抢走之前 M
执行完成，则继续执行 G 任务后续资源；第二种 P 被抢走，当前 G 任务打包放回到队列里继续休眠。

例子

程序刚启动的时候，只有 M0 和 P0 用来执行 main goroutine。当我们在 main goroutine 里用 go func 时，它会放到
P0 本地队列或者 `runnext` 中。调度器还做另外一件事，它会尝试唤醒其他等待的 M，唤醒分两种状态。第一种状态是没有多余的 M，P
是空闲的，这时候调度器会创建新的 M 和 P 绑定执行任务。也就意味着创建任务的时候，还要唤醒。M1 把任务执行完，没有其他任务就与 P 解除关系，M1
放到空闲队列里。main goroutine 创建 G2，调度器会从空闲队列里唤醒 M 然后找空闲 P 配对执行。

假设 G3 任务要执行系统调用。系统调用会从用户空间切换到内核空间，可能需要很长时间，系统监控会检查发现 G3 执行很长时间，它会把 P1 拿走，M1
还在执行系统调用，M1 执行完成后，发觉 P 令牌丢了，它就把 G3 任务状态保存放回队列。P1 被系统监控拿走，P1
会检查是否有其他的任务需要执行，如果有 G4 要执行，它会再创建 M2，P1 和 M2 绑定执行 G4。如果多次这样的系统调用，M
的数量在不停的增长，空闲的 M 数量也可能在不停的增长。正常情况下 M 的数量和 P 的数量可能不是一致的。并不是 P 和 M 相等是最好的状态，是 M
的数量在长期运行后维持一个稳定的数字尽快的完成任务，然后空闲下次唤醒尽可能是从空闲队列里拿而不是新建，也就是空闲队列的 M
能满足所有新建任务的执行，这是最合理的，也就说线程数量维持在一个稳定的状态下是最合理的。

这样调度方式可以确保任务阻塞不导致整个系统停滞，因为有大量的任务需要调度执行。任何时候阻塞时间会被剥夺，这是并发算法核心基础。

比如 `gomaxprocs`P 的数量是 4，空闲 P 的数量 `idleprocs`，线程总数量 `theeads`
应该保持相对稳定的数字。线程更细包括自旋线程，当前处在正在查找任务的状态，这时候不要唤醒或者新建，自旋线程直接取任务。空闲线程就是在空闲队列里的线程。线程总数量
`theeads` 数字累积到很大不会释放，所以逻辑如果写的不好的话线程数量非常多的情况下是个麻烦，会造成操作系统需要维持这些线程，每个线程还有 G0 的
2KB
内存也是消耗。还有一种可能会释放，把线程锁定，执行完忘记解锁线程处于一种死锁状态，没法复用，调度器会释放这个线程。只有在这种出错的情况下会释放，正常情况不释放。所以写代码的时候一定要小心，当出现
`theeads` 非常多的时候，逻辑实际上是有问题的。

### 调度循环

M 从它启动开始，就会进入一个调度循环状态。首先执行 `sched` 函数，这个函数通过多种方式查找 G 对象，本地队列、全局队列、各种各样事件，都是用
G0 栈来处理，属于系统指令。找到 G 任务以后切换到 G1 用户栈，开始执行 G 任务自带的 fn 函数，把参数传进去执行，执行完成通过 `goExit`
方法完成一些清理操作，清理操作完成后再回到循环，实际上就构成所谓的调度循环。如果很长时间找不到任务就把 P 释放出来，M
放回空闲队列。当下次被唤醒的时候会重新进入调度循环。

M 拿到 P 以后处于一种激活状态，就会调度循环，其实就是一直在循环，从队列里查找 G，拿到 G 以后用参数去执行，这样一来构成调度器里三个基本的角色。P
用来控制并发数量它是执行所需要的令牌，必须拿到 P 才能执行。M 是真正的执行单位，每个 M 代表 1 个线程，所有的代码都要交给线程去执行。M
必须拿到一个 P 令牌才可以执行，剩下的处于闲置状态。

调度循环执行过程：

首先创建一个 G 对象，G 对象等待执行被保存到当前 P 的本地队列或者全局队列中。

P 对象执行执行序，执行完唤醒 M，这时候唤醒可能有两种，第一种可能是以前创建过现在是休眠状态，第二种可能是没有创建就新建一个。

M 查询空闲的 P，如果有空闲 P 的话，和当前创建的 G 对象绑定，接下来这个 M 就会执行调度循环。

调度循环就是 P 一直重复执行形成一个循环：找到 G，执行 G，完成后清理现场；继续找新的 G 对象。

![](/Users/linmi/Documents/Work/GitChat/ 专栏 / 李永京 / 重学 Go 语言：进阶篇 / 审稿
/images/goroutine_g.png)

通过 `runtime.GOMAXPROCS` 调整并发数量，实际上修改 P 的数量，修改 P 的数量也就意味着可以控制同时可以被调度执行 M 的数量。M
一旦拿到 P 以后被唤醒进入调度循环，就是不停的用类似死循环的方式从队列里去查找 G 任务，执行 G。

不要在程序运行中途改并发数量。中途改相当于热插拔 CPU，会引发
STW，把整个进程中的所有的状态全部冻结，等任务队列重新调整完重新启动这个世界造成很大的性能问题。

### 连续栈

对于 goroutine 这种栈和系统栈实际上有很大区别。goroutine 栈是 G 对象自带的，执行时 M 会绑定这个栈，由于初始化只有
2k，创建成千上万 G 任务消耗也非常小，但是执行时栈 2k 可能不够用，goroutine 栈空间在不够用的情况下必须扩容
Grow，扩容有两种方式，一种叫分段模式，一种叫连续模式。

![](https://images.gitbook.cn/6J8lhH)

#### 什么是分段栈

分段模式其实很简单，比如需要扩容时直接分配一个栈空间，构成链表结构，处理后抛弃回到当前栈。这种分段模式的优点是当前栈上面的数据不需要任何处理，只需要把新的栈帧分配到新的栈空间，执行完把新的空间抛弃。

#### 分段栈的问题是什么

分段栈带来的问题是执行一个循环，分配空间不够用需要分配新的栈帧，执行结束释放新的栈帧，这样造成每次循环都频繁的分配内存和释放内存形成热点效应，分段模式存在热点效应，这个热点效应在某些时候会造成很严重的性能问题，所以
Go 语言从 1.4 版本就弃了分段栈的概念而改用新的方式叫连续栈。

#### 连续栈如何实现

连续栈如何实现，比如一段当前栈空间，当内存不够的时候，它会在另外的空间创建原来 2
倍大小的栈空间，然后把当前栈的数据全部拷贝过来，抛弃原来的空间，接下来循环执行的时候新的空间显然够用，不会形成热点效应。

#### 连续栈回收

我们先想两个问题。

问题 1，用拷贝的方式不会出问题么？栈上有指针的，拷贝过来以后指针会不会出问题。

问题 2，创建 2 倍栈空间执行完后面的内存算不算浪费，需不需要做收缩处理？

首先为什么可以做拷贝操作？任何时候栈上有两种数据，第一种栈本身的数据，第二种栈上有指针指向堆上某个对象。在栈上访问所有数据都是 SP 加上偏移量，只要把
SP 原位置改掉执行新位置，栈里面偏移量没有发生变化。栈上指针指向堆上对象，栈上保存的地址值实际上是个整数。

第二个收缩问题，在垃圾回收的时候会检查所有的栈空间，它会计算当前栈空间利用率，runtime 会设定一个预值，比如当前栈空间利用率是 50%
做压缩处理，压缩处理无非就是再分配小一点的栈，把里面数据再拷贝过去，把原来栈释放掉，所以这个称之为连续栈或者拷贝栈，通过这种方式动态调节栈的大小。

分段栈的优点对于内存比较节约，因为不用内存释放，缺点一旦形成热点效应时候性能会比较差。连续栈的优点就在于一次性创建一大块空间后面不需要重复分配，缺点就会有一定的内存浪费。任何一种方案都会有优点缺点，多处时候我们的选择是空间换时间，缓存本身就是用空间换时间，在现代不管软件设计还是硬件设计，Cache
这个词用在各种各样的层面。

#### 连续栈扩张问题演示

    
    
    func grow() {var d [1<<20]byte
        for i := 0; i < len(d); i++ {d[i] = 1
        }
    }
    
    func test() {
        x := 100
        grow()x++}
    
    func main() {test()
    }
    

当我们执行 test 函数的时候，本地只分配了局部变量 x，然后调用 grow 函数，这个函数里创建了一个大的数组，这种大的数组会导致当前栈不够用，Go
语言的线程栈就有 2k，必然做扩容。我们跟踪一下当执行完 grow 函数的时候 x 的地址会发生变化，寄存器 SP 的位置肯定也会发生变化。

    
    
    $ go build -gcflags "-N -l" -o test
    
    
    
    $ gdb test
    $ l
    $ l
    $ b 15 #打断点
    $ r #执行
    $ p/x &x #输出 x 地址
    $ p/x &rsp #输出 sp 寄存器地址
    $ b 16 #打断点
    $ c #继续执行
    $ p/x &x #输出 x 地址
    $ p/x &rsp #输出 sp 寄存器地址
    

我们执行 grow 函数以后会发生扩容，按照上面说的理论，很显然 x 被拷贝到另外一个位置了，SP 是指向新的内存段上面去。对比这 x 地址和 sp
寄存器地址可以看到这个内存位置的确发生了改变，这其实就是很典型的栈空间发生了改变，因为它被搬移了另外一个位置，数据全被拷贝过去了，做了一次重新指向。这是很简单用来测试连续栈扩张操作。

### 小结

我们现在知道 G、M、P 基本工作方式，它实际上是用抽象的组件管理不同的状态执行，这样的优点是整个 runtime
可以脱离操作系统来构建和操作系统无关的执行控制，所以 runtime 更像是微型的操作系统。

类似虚拟地址空间对物理内存做了一次抽象，摆脱了物理内存种种限制。64 位虚拟地址空间非常的大摆脱物理内存限制，简化成虚拟地址空间只创建不释放。

同样的，goroutine 的 G、M、P 模型是为了摆脱对操作系统的依赖，我们不用再去考虑线程，不用再去考虑并发对于核的处理。而且任务 G
每次对栈使用非常小，初始化栈可能 2K，所以可以创建成千上万的 G 对象，而且 M 可以创建很多，因为 M
本身没有创建很大的系统栈，对于操作系统来说消耗非常的小。另外 M 创建后放到队列中不释放，进入休眠状态的 M
对象在内核中虽然有句柄消耗但是没有内存消耗，而且它处于休眠状态操作系统并不分配时间片，因为 M 多路复用，所以 M 数量可以很多并不导致操作系统性能。

我们现在 GMP
建立这样一个抽象的概念，工作状态是怎么回事，线程怎么调度的，怎么执行的，然后考虑更多的细节，比如占内存怎么扩容，怎么收缩的。就会涉及到另外一个问题，M 自带
G0 栈内存用来执行系统指令的，G 自带栈可以从 2KB 扩容到
1GB，那么怎么扩容呢？实际上重新分配两倍的内存，然后把数据拷贝进来，栈指针指向新的地址，原来的释放掉，称之为拷贝栈。收缩也一样，创建小一点的块，把数据拷贝进来，用它来替换原来的释放。所以写逻辑需要频繁的扩容可能会导致性能的问题。

