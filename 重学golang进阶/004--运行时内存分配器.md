---
html:
  embed_local_images: false
  embed_svg: true
  offline: false
  toc: true
print_background: false
export_on_save:
  html: true
  puppeteer: true
---
我们在做架构设计的时候，时时刻刻记住抽象。早期编码没有驱动程序一说，屏幕显示文字则需要把数据写到显卡内存里输出，后来操作系统做一层抽象，我们不需要和硬件打交道，只和驱动程序API打交道。可以同时运行多个程序，操作系统基于时间片切换，从协作式调度变成抢占式调度，这其实也是抽象。

### 运行时

现代编程语言大部分有运行时，类似在操作系统之上再抽象出一层虚拟机，它接管着很多东西，比如内存、垃圾回收、甚至包含并发任务调度。操作系统抽象硬件，编程语言抽象操作系统，这是一种设计上的理念，让变化被缩小的某局部的范围内，用一种规则把变化的部分约束起来。

运行时抽象为了规避不同平台操作系统，因为很多语言都需要跨平台，不可能针对不同的操作系统让用户写出各种各样的代码。早期使用C语言开发跨平台程序时候，需要针对不同平台、不同操作系统。运行时通过抽象层面上的概念，让我们的代码同运行时打交道，类似和虚拟地址打交道一样，我们不需要关心物理层面、操作系统层面概念，使代码非常的简单。

### 自主实现内存管理

为什么要自主管理内存？操作系统管理内存有哪些问题？

C语言由操作系统分配内存，调用`malloc`、`free`、`new`、`delete`系统调用向操作系统申请或者释放内存。向操作系统申请内存时，操作系统需要在mmu建立映射，建立映射后给内存读写数据。

由操作系统管理内存，可以避免每种语言实现内存管理，操作系统为什么不管理内存呢？最主要原因是操作系统不知道怎么内存复用，对于操作系统来说，内存复用意味着内存不释放。操作系统运行着各种各样的应用程序，不同语言对于内存使用方式不一样。不同的操作系统、不同的编程语言之间的差异化很难控制。

C语言是通过操作系统分配内存，现代语言内存管理的思路大致差不多，因为内存分配器和垃圾回收器发展到一定程度都殊途同归，相互借鉴都差不多。

在语言中实现内存分配有很多优点：

第一向操作系统申请内存涉及到系统调用浪费时间。减少系统调用造成的性能。

第二申请的内存不利于复用，不容易管理碎片化申请。自主实现内存复用体系。

第三和垃圾回收器的配合，垃圾回收器迭代更新，内存分配器也需要迭代更新，内存分配器实现并发。

### 内存管理流程

内存管理简单方式是什么？我们分4小点来说明：

**1\. 分配内存**

每个程序有一段虚拟地址空间，它会被映射成不同的块，比如.text段、.data段、mmap。如下图所示：

![](https://images.gitbook.cn/jhs71M)

当使用`mmap`系统调用在虚拟地址空间上申请1MB内存空间，把这1MB内存空间按8字节单位分配相同大小的块，每块都是8字节，使用链表把这些块管理起来。

**2\. 使用内存**

使用内存的时候，最小单位在1-8字节之间不需要分配，直接在链表上取出来直接使用。比如需要1字节空间，直接取8字节的空间块使用其中1字节，剩下7字节不用，使用完把8字节块重新放回链表中，接下来又可以被1-8字节使用。

**3\. 复用策略**

为什么按照8字节单位分配？这是一种策略，它适用1-8字节的内存分配的复用。

如果分配大小不相等的块会出现什么状态？比如依次分配1字节、3字节，1字节释放后，3字节还未释放。下次需要1字节才能复用之前分配的1字节，这样分配很容易造成空间越来越小形成碎片化。

Java语言和C#语言对内存压缩，内存回收器把使用的内存压缩移到左边，空出右边方便再次分配。

C语言和Go语言不能对内存压缩，因为支持指针，移动造成地址发生变化，大地址移到左边变成小地址。

所以内存分配最优化的方法是按照固定大小分配，简化内存管理和复用。例如以8字节策略，8字节、16字节、32字节，规格1以8字节为单位的块，规格2以16字节为单位的块，以此类推，有60多种方式可以管理几万种不同大小分配。分配内存时先计算对象大小，比如11字节，然后找到对应的规格，比如规格2，直接在规格2取内存块，使用后再放回规格2。这样内存复用很方便，取内存和放内存也很方便。规格大小的块也不易形成碎片化。

**4\. 内存复用**

实际如何申请呢，我们逆向推导这个过程。比如需要分配15字节内存，首先找到对应的规格，规格2对应16字节，检查规格2是否有剩余可用的块，有的话直接取出来，没有则检查是否有大内存自由块，有的话批量分配16字节放入规格2，取一块使用。没有大内存自由块则向操作系统申请，一次申请1M自由块。这里注意申请一大块内存实际申请的是虚拟地址空间不是物理地址空间，申请1M虚拟地址空间，操作系统会及时返回，只有在写数据时操作系统才会MMU映射分配物理地址。尽管只要16字节也申请1M，申请后批量分配16字节放入规格2，这样减少向操作系统申请的次数，达到内存复用优化。

![](https://images.gitbook.cn/ecmIvh)

还有另外一种复用优化，假设分配100块16字节内存块很长时间没有使用，就把这些内存块还原成大内存自由块，自由块可以按需分配8字节、32字节、64字节其他规格。

内存复用有两种体系，第一种是规格相同的复用，第二种是把内存块还原成自由块，自由块可以分配其他的规格。

### 内存管理解决什么问题

第一个内存复用。为什么解决内存复用？通过复用减少频繁的向操作系统申请，占用更多的空间延长内存的使用时间。相当于原来每次申请1M释放1M，用空间换时间的方式，一次申请10M重复使用。这种利用复用优化性能方式很常见，比如建立对象池，连接池。

第二个内存碎片化。频繁的申请内存和释放内存容易碎片化。理论上说，一次性申请大块内存可以做到连续分配，释放时可以把相邻的空间从小块变成大块以适应更多的分配需求。通过相邻的地址空间的合并减少碎片化。所以进行内存分配和释放的时候，尽可能使用连续地址空间，解决碎片化的问题。

### 一些巧妙的设计思想

  1. 对齐：按范围来划分对象

理论上最优化的复用状态是所有对象大小一样，现实不存在这种情况。以特定的大小做归纳，把小对象用类似的概念进行聚类。比如8字节存储1-8字节，16字节存储9-16字节。最大8字节使用1字节浪费7字节。用空间换时间，按某个范围划分，不关心多少字节、只关心某个范围，分配到某个范围里，管理的对象具体化。比如各种存储设备最常见称之为块状设备，按块划分易复用，每个块能解决多种需求。很多硬件、操作系统都是按照特定长度对齐，8字节对齐是很常见的需求。

  2. 虚拟地址空间如何使用

每个进程有一个虚拟地址空间，内存分配在某段虚拟地址空间内就能保证是连续的。所以需要解决下面问题：

**第一个问题从哪个位置开始合适？**

让操作系统随机开始，保留一段地址空间，如果失败，加上或者减去偏移量重新选择。

**第二个问题中间被打断怎么办？**

如果连续的方式不行使用分段的方式。空间扩展尝试同一方向扩展，失败则换个相反方向扩展，这样空间还是连续的。操作系统随机从两个方向扩展的方式称之为稀疏堆。

**第三个问题怎么记录上次分配的位置？**

使用类似反查表存储内存状态，比如：

  1. 每次分配一个自由块而不是分配一个对象内存。如果按对象分配，位置存在竞争效应，解决方法就是批处理，预分配内存，用单向递进的方式分配自由块解决位置的竞争。
  2. 使用一个数组。数组存储内存指针指向自由块，自由块有各种状态，比如当前使用多少内存、是否是空闲状态等，形成类似反查表的作用。自由块的内存起始地址减去初始位置得到偏移量，偏移量按页大小对齐作为数组索引。这样的优点是只需检查数组就知道内存分配的信息、检查相邻的两项的是否空闲可以合并成大块内存。通过反查表实现碎片化问题。
  3. 使用另一块内存存储垃圾回收的状态。

第四个问题一直分配，释放重用，理论上内存占用会越来越大。

一种思路，记录虚拟地址空间，释放内存，用重新分配的方式来补偿。
另一种思路Linux本身提供自动化的功能，已经分配虚拟内存不使用时向操作系统发送一个建议，从某点到某点的地址不再使用，建议操作系统可以解除它的物理内存。

### 内存分配器思想原理

之前了解了内存管理流程，Go语言运行时怎么具体管理的呢？我们从总体上用一张图鸟瞰框架：

![](https://images.gitbook.cn/sgWE89)

下面从三个机构职责分别阐述：

**1\. Heap机构的职责**

操作系统的内存空间称之为堆Heap，向操作系统申请的内存空间称之为自由块，最小的自由块是1M，Heap很多自由块。这些自由块的管理方式很简单，对于内存来说它的分类方式有两种，一是按照字节来分，比如1字节、3字节，这种方式比较琐碎，数量太多不方便管理。最好的方式自由块以页为单位，操作系统管理内存的单位是页，一页可能有8K、4K、2K，假设以8K称之为1页。我们把1页的自由块放在规格1的链表中，把2页的自由块放在规格2的链表中，以此类推，把规格1、规格2等链表构成数组。比如向堆申请2页自由块，从数组中以2为下标找到链表，从链表里取。换句话说，向堆释放一个自由块，自由块是多少页就放回到对应链表中。

普通规格的自由块称之为小对象，超过某个阈值的自由块称之为大对象，每种语言阈值大小定义不一样。比如100M，100M以上的自由块很少，所有大对象分配在一起。实际上程序中小对象的数量最多，大多数分配内存都在1K以下。大对象数量非常的少，没有必要复杂管理。所有小对象以数组下标为单位在链表数组里，所有大对象在单独链表中。

对于堆来说，只做两件事情，第一件事情是申请自由块，首先检查链表有没有大小合适的，没有的话检查索引大的链表。比如申请10页大小的自由块，索引1-9都没有，只能检查大于1等于索引10，10没有检查11，11没有检查12，如果12有自由块，申请的是10页，把剩下2页放到2的数组，取走10页。所以向堆中申请自由块没有大小合适，会做内存切割。为什么没有10页的情况下不直接向操作系统申请？因为尽可能复用空闲自由块，用完之后再向操作系统申请。

第二件事情是释放自由块，自由块归还Heap需要合并成大块，因为大块可以适应不同的变化。比如释放10页时把10页和2页合并成12页，12页能适应更多种变化。

所以向堆申请自由块多的话做内存切割，释放自由块时尽可能内存合并。堆是用来管理大块的自由块，大块自由块以页为单位划分到不同的地方。

**2\. Central机构的职责**

分配自由块的机构叫 Central ，在 Central 中分配方式有很多，一种方式是每个 Central
中有各种大小的自由块，这样有很多问题，一是各种规格的申请请求阻塞造成排队，二是需要考虑每种大小自由块什么时候准备并且准备多少数量。换句话说，有很多这样的
Central ，申请请求也不知道应该去哪个 Central 申请。

最好的方式是每个 Central
只提供同一种规格的自由块，这是很简单的分布式做法。比如1页的、2页的、以此类推。申请请求快速分流，不会造成阻塞，但是同一时间申请请求过多只有排队。在
Central 中取自由块需要加锁，相比第一种方式同一 Central 有各种规格都要锁，第二种方式相同规格只要1个锁，从而达到分散锁目的。

**3\. Cache机构的职责**

申请请求具体是什么流程呢，当申请请求的是1页自由块则去1号 Central 申请，申请2页自由块则去2号 Central 申请。

申请请求关联一个缓存 Cache
，这个缓存保存同一规格自由块，为什么要建立缓存呢？根据相同的理论，一个算法频繁执行可能使用相同规格的内存块，频繁执行场景内存分配很大概率有一定的规律。比如循环或者频繁执行某个函数，这个函数使用1、3页规格的内存块，频繁执行时1、3页就要频繁的分配，换句话说这个申请请求就会频繁向1、3号
Central
申请自由块。为了避免频繁的操作影响程序性能，最好的方式是批处理取自由块，申请1页时一次性取回10个1页，申请3页时一次性取回10个3页，这样原本需要申请1页和3页共20次，需要抢20次锁，现在只需要申请两次每次取10个。

所以 Central 做一次分流， Cache 一次拿回更多的自由块做第二次分流，减少同一个 Central 里大量排队的行为。有这样的场景，高峰期时申请
Central 需要排队，如果每次申请一批就不用花费很长时间排队，这个 Central 实际上就被分流了，这是第二次分流。

还有因为执行最终要绑定到当前执行线程 Thread
上，缓存就和线程绑定，线程从它绑定的缓存分配和释放自由块，缓存操作是无锁操作。因为有一堆请求去Central、Heap级申请需要锁。 Cache
级不需要锁。所以 Cache 每次去 Central 申请10个加一次锁，接下来使用10次不需要锁。所以利用三级机构分解锁。

**4\. 三个机构的释放平衡**

如果缓存积累大量的自由块。比如申请1页自由块取回10个，但每次操作只使用1个自由块，剩下9个长时间空闲。由垃圾回收器来触发回收操作，垃圾回收器把9个自由块释放放回
Central ，Central 给其他线程使用，这是做第一级平衡。

某段时间频繁使用2号 Central ，造成2号 Central 产生大量的自由块，如果 Central
积压大量自由块，内存分配器会找出相对完整的大块自由块归还到 Heap ， Heap 把这些自由块分配其他规格，这样在不同的 Central 之间做平衡。

这就涉及两级平衡，第一级是 Cache 不能有大量的积累，尽可能归还 Central 。第二级是不同的 Central 之间的平衡，有可能 Central
有大量的闲散资源，把这些闲散资源交还给 Heap ， Heap 把这些资源分配其他规格 Central 。

**5\. 总结**

内存分配的完整流程首先检查 Cache 里有没有自由块，有的话直接返回；没有的话计算向哪个 Central 申请，如果 Central
有则取回一批，如果没有，则向Heap申请大块自由块切割，如果Heap没有多余的自由块，Heap向操作系统申请。Go语言在初始化时建立一个静态表，通过静态表知道一次取多少个，这个数字是基于大量的统计得到的，有些语言根据程序运行期动态调整这个数字。

任何时候内存管理都会涉及两个核心问题。

第一个快速分配，比如实现无锁操作或者减少锁。因为 Central 被很多Cache共享，操作数据必须加锁处理，Heap 被很多 Central
共享，操作数据要加锁。

第二个尽可能在内存复用方面做到平衡。快速操作意味着用批处理代替单次处理实现性能提升，但是批处理会浪费大量的资源。所以一来用批处理来实现快速分配操作的性能，一来实现内存节约避免快速消耗，需要在中间找到平衡点。

内存分配器常见有tcmalloc、jemalloc、supper三种，很多应用都是基于前两种，比如redis使用前两种替换系统调用的内存分配提升性能。mysql建议使用前两种内存分配器。它们实现原理大体上有些类似，只是细节处理上有些区别，选择一种深入了解有助于内存分配器深入认识。

Go语言内存分配模型基于tcmalloc。tcmalloc是google开发的快速内存分配器，它本身就是基于并发设计的一种内存分配模型。它使用了三级机构机制既照顾了快速分配又照顾了内存节约。

### Go语言内存的管理

Go语言基于并发调用，按照GMP的原理，M相当于线程用来执行，P相当于处理器用来管理资源。P分配对象需要地址空间，理论上每个P需要多种资源，P通过
Cache 管理资源。P只与单个线程绑定，分配内存不需要加锁，还有基于效率考虑每次分配一批。

中间组件 Central 同时为多个P提供 Span，这个级别需要加锁。

Central 提供 Span ，Cache只负责分配，职责分开。回收P中空闲的 Span 完成第一次资源平衡，相同规格 Span
在不同的P之间进行调度平衡。

Heap 负责向操作系统申请内存。一次分配 Span，小块叫做 object，大块叫做
Span，回收合并在不同规格之间进行调度平衡。保证内存按照当前需求的方式来进行平衡。

通过三级结构，Cache 通过批量的方式把内存交给P形成本地快速无锁分配，达到缓存的作用。Central保证同一规格内存在不同的P之间去平衡。Heap
回收合并充分利用申请的内存。空间换时间实现高速并发分配，高速并发分配的问题就是锁竞争。

### 如何释放物理内存

有各种原因Central
分配大量的内存退还Heap，需要把大量的Heap还给操作系统，这涉及物理内存释放。一种方式告诉操作系统内存彻底不使用可以释放，这种释放是虚拟地址和物理地址全部解除，这种方式会造成地址空间形成很多空洞，这些空洞很难复用，这种释放算法不太合理。

Go语言怎么释放呢？Go语言不释放虚拟地址，它只是向操作系统提个建议，某一段虚拟地址暂时不用，可以解除虚拟地址和物理地址的mmu映射，不同操作系统可能会触发两种行为。

第一种全部释放。Windows没有建议解除，只能全部释放。Linux觉得物理内存不够存在大量的换入换出操作，则解除映射。
第二种不释放。Linux觉得物理内存足够使用，忽略建议不释放。检测RSS发现一直没有减少就是操作系统没有释放。

在Heap上不释放虚拟地址，分配时使用之前解除的虚拟地址，有可能会引发两种行为。

第一种物理地址映射没有解除直接使用；
第二种物理地址被解除，引发操作系统缺页异常，操作系统补上物理内存。这个过程对用户空间不可见，在用户空间觉得这段内存根本没有释放过。因为用户空间是虚拟地址，虚拟地址是否映射物理地址对用户逻辑不关心，它由操作系统管理，操作系统通过mmu建立映射。

所以保留虚拟地址空间分配，解除物理地址映射。一旦解除相当于这块虚拟内存没有建立映射。我们再向这个地址写数据分两种状态，第一种状态是它已经建立物理内存的映射，直接读写；第二种状态是没有建立物理内存的映射，引发缺页异常，操作系统会自动补上映射。操作系统申请内存也是机会主义分配。

利用sysmon监控。定期扫描所有的自由块，如果闲置超过5分钟要么手动释放物理内存，要么向操作系统发送建议。从虚拟地址空间上看，自由块依然存在，从物理地址空间上看，地址空间已经释放，这样就完成了对物理内存的释放。

